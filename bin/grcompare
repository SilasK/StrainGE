#!/usr/bin/env python
import os
import numpy as np
import re
import itertools
import gzip
import cPickle
import argparse

info_line = re.compile(r'##INFO=<ID=([A-Za-z0-9]+),Number=([0-9]+|\.),Type=(\w+),Description="(.*)">')
filter_line = re.compile(r'##FILTER=<ID=([A-Za-z0-9]+),Description="(.*)">') 

bases = "ACGT"

# globals
min_qual = 5
min_mq = 5
min_confirm = 50
consensus = 0.9
verbose = False

class Pileups:
    def __init__(self, pileups=None, name=None, keepCovered=True):
        self.pileups = {}
        self.reads = {}
        self.name = name
        self.length = 0

        for pileup in pileups:
            if verbose:
                print "Adding pileup", str(pileup)
            self.add_pileup(pileup, keepCovered)
            self.length += 1

    def add_pileup(self, pileup, keepCovered=True):
        """Add pileups based on scaffold and position"""

        if keepCovered and not pileup.covered():
            return

        chrom = pileup.chrom
        if chrom not in self.pileups:
            self.pileups[chrom] = {}
        pos = pileup.pos
        self.pileups[chrom][pos] = pileup

        # store reads and their positions, match back to pileup
        for read in pileup.reads:
            if read not in self.reads:
                self.reads[read] = {}
            if pileup.reads[read][1] == 'del':
                continue
            readpos = pileup.reads[read][0]
            if readpos in self.reads[read]:
                print "Duplicate read position found", read, readpos
                print self.reads[read][readpos]
                print chrom, pos
            self.reads[read][readpos] = (chrom, pos)
    
    def __len__(self):
        return self.length
    
    def __str__(self):
        return "<Pileups Class> containing %i pileups" % self.length

class Pileup:
    """
    Class to process pileup information; that is,
    all the alignment information corresponding
    to a given reference coordinate.
    """

    def __init__(self, chrom, scaffold, pos, pileup_reads=None):
        """
        :param scaffold: reference sequence
        :param pos: coordinate in reference (0-based)
        :param pileup_reads: pileup objects from pysam
        """
        self.chrom = chrom
        self.scaffold = scaffold
        self.pos = pos
        self.reads = {}
        self.count = 0
        self.unmapped = 0
        self.bad = 0
        self.mq_total = 0
        self.mq_ss = 0
        self.qual_total = 0
        self.qual_ss = 0
        self.ref_count = 0
        self.ref_qual = 0
        self.ref_qual_ss = 0
        self.ref_mq = 0
        self.ref_mq_ss = 0
        self.hc = False
        # reads with other than reference base; list of tuples (base, qual, mq)
        self.others = {}

        self.refbase = scaffold[pos]
        if not pileup_reads:
            print "No reads for pileup"
            return
        for read in pileup_reads:
            self.add_read(read)

    def add_read(self, read):
        """Add a pysam.PileupRead object to this pileup"""
        alignment = read.alignment

        # if this is a paired read, make sure the pairs are properly aligned
        if (not alignment.is_paired) or (not alignment.is_proper_pair):
            self.bad += 1
            return

        # restrict ourselves to full-length alignments (not clipped)
        if alignment.query_alignment_length != alignment.query_length:
            # alignment is clipped
            self.bad += 1
            return

        # check that inferred insert size is at least read length
        tlen = alignment.template_length
        if abs(tlen) < alignment.query_length:
            self.bad += 1
            return

        # get base quality (note this is next base if deletion)
        pos = read.query_position_or_next
        qual = alignment.query_qualities[pos]
        if qual < min_qual:
            self.bad += 1
            return

        # base call must be real base (e.g., not N)
        base = alignment.query_sequence[pos]
        index = bases.find(base)
        if index < 0:
            self.bad += 1
            return

        # check for decent mapping quality
        mq = alignment.mapping_quality
        if mq < min_mq:
            self.unmapped += 1
            return

        # We're good! Update the pileup stats...
        self.count += 1
        self.mq_ss += mq**2
        self.mq_total += mq
        self.qual_ss += qual**2
        self.qual_total += qual
        # keep track of the reads in this pileup and the position in that read
        self.reads[alignment.query_name] = pos

        if read.is_del:
            # using N as marker for deletion...
            # workaround until we can write actual deletions into vcf format
            self.add_other("N", qual, mq)
        elif base == self.refbase:
            self.ref_count += 1
            self.ref_qual_ss += qual**2
            self.ref_qual += qual
            self.ref_mq_ss += mq**2
            self.ref_mq += mq
            
        else:
            self.add_other(base, qual, mq)
            if verbose:
                print base, qual, mq

    def add_other(self, base, bq, mq):
        """
        Keep information about bases in pileup which differ from reference.
        :param base: alternate base or 'del' for deletion
        :param bq: base quality
        :param mq: mapping quality
        :return:
        """
        if not self.others:
            self.others = {}
        if base in self.others:
            (count, qss, mqss, qual, mapqual) = self.others[base]
        else:
            count = 0
            qual = 0
            mapqual = 0
            qss = 0
            mqss = 0
        count += 1
        qual += bq
        mapqual += mq
        qss += bq**2
        mqss += mq**2
        self.others[base] = (count, qss, mqss, qual, mapqual)

    def covered(self):
        """Does this pileup have enough data to consider this locus covered?"""
        # this seems wrong
        #return self.ref_qual >= min_confirm and self.count > self.bad
        
        # this seems better...
        #return self.qual_total >= min_confirm and self.count > (self.bad + self.unmapped)

        # why do we care if there are also bad reads as long as there are good ones???
        return self.qual_total >= min_confirm

    def unmappable(self):
        """Good quality sequence, but can't be mapped"""
        return self.unmapped > self.bad

    def ref_fraction(self):
        """Fraction of evidence which supports reference base"""
        if self.qual_total:
            return float(self.ref_qual) / self.qual_total
        else:
            return 0

    def confirmed(self):
        """Does this pileup confirm the reference?"""
        return self.ref_qual >= min_confirm and \
               (self.ref_qual == self.qual_total or self.ref_fraction() > consensus)
    
    def _get_best_snp(self):
        """Returns the SNP with the highest sum of RMS base quality and mapping quality, if two are qual, return higher count. All else equal, alphabetical."""
        best_snp = None
        best_score = 0
        best_count = 0
        if len(self.others) == 1:
            return self.others.keys()[0]
        for snp in self.others:
            # score is just sum of RMS(BQ) and RMS(MQ)
            score = sqrt(float(self.others[snp][1])/self.others[snp][0]) + sqrt(float(self.others[snp][2])/self.others[snp][0])
            count = self.others[snp][0]
            if score > best_score:
                best_snp = snp
                best_score = score
                best_count = count
            elif score == best_score:
                if count > best_count:
                    best_snp = snp
                    best_score = score
                    best_count = count
                elif count == best_count:
                    if verbose: print "Warning: multiple SNPs have same score and count!"
                    return False
        
        return best_snp
        
        #return max(self.others.keys(), key = lambda snp: (sqrt(float(self.others[snp][1])/self.others[snp][0])+sqrt(float(self.others[snp][2])/self.others[snp][0]), self.others[snp][0], snp))
    
    def sort_alts(self):
        return sorted(self.others.keys(), key = lambda snp: (-sqrt(float(self.others[snp][1])/self.others[snp][0]) + sqrt(float(self.others[snp][2])/self.others[snp][0]), -self.others[snp][0], snp))
    
    def base_call(self):
        """Call another base...just print out stats for now"""
        rf = self.ref_fraction()
        if rf < consensus:
            if verbose: print 'SNP?', self.pos, self.scaffold[self.pos], self.count, self.bad, rf, self.others
            
            if len(self.others) == 0:
                if verbose: print "No evidence of SNPs"
            else:
                # get SNP with highest proportion if >1 SNP
                base = self._get_best_snp()
                #if base and self.others[base][0] >= (consensus * self.count) and self.others[base][3] >= min_confirm:
                if base and (float(self.others[base][3]) / self.qual_total) >= consensus and self.others[base][3] >= min_confirm:
                    # 90% of base quality matches SNP
                    if verbose: print "SNP confirmed %s" % base
                    return base
                else:
                    # no consensus
                    if verbose: print "No confirmed SNP"
        
        return None
    
    def high_coverage(self, high):
        """Flag pileup for too much coverage"""
        self.hc = self.count > high
    
    def __str__(self):
        return "<Pileup n=%d rc=%d bad=%d rq=%d/%d mq=%d/%d o=%s>" % (self.count, self.ref_count, self.bad,
                                                                      self.ref_qual, self.qual_total,
                                                                      self.ref_mq, self.mq_total, str(self.others))





class VCF:
    def __init__(self, name=None, reference=None, source=None, date=None):
        self.name = name
        self.reference = reference
        self.source = source
        self.date = date
        self.info = {}
        self.filters = {}
        self.data = {}
        self.positions = 0
        self.passed = 0
        self.confirmed = 0
        self.snps = 0
    
    def add(self, line):
        temp = line.strip().split("\t")
        chrom = temp[0]
        pos = int(temp[1])
        id = temp[2]
        ref = temp[3]
        alt = temp[4]
        if temp[5] != '.':
            qual = int(temp[5])
        else:
            qual = 0
        filt = temp[6]
        if filt != "PASS" and filt not in self.filters:
            print "Unknown filter", filt
            return
        inf = temp[7]
        info = {}
        for pair in inf.split(';'):
            key, value = pair.split('=')
            if key not in self.info:
                print "Unknown info key", key
                continue
            
            number = self.info[key]['Number']
            _type = self.info[key]['Type']
            if _type == 'Float':
                convert = float
            elif _type == 'Integer':
                convert = int
            else:
                convert = str
            if number == '1':
                info[key] = convert(value)
            else:
                _value = [convert(v) for v in value.split(",")]
                info[key] = _value
        
        if chrom not in self.data:
            self.data[chrom] = {}
        
        if pos in self.data[chrom]:
            print "Warning: position %s, %d found more than once" % (chrom, pos)
        else:
            self.positions += 1
        
        self.data[chrom][pos] = { 'ref': ref, 'alt': alt, 'qual': qual, 'filter': filt, 'info': info }
        if filt == 'PASS':
            self.passed += 1
            if alt == '.':
                self.confirmed += 1
            else:
                self.snps += 1
        else:
            self.filters[filt]['count'] += 1
    
    def get_confirmed(self):
        confirmed = []
        for chrom in sorted(self.data):
            for pos in sorted(self.data[chrom]):
                if self.data[chrom][pos]['filter'] == 'PASS' and self.data[chrom][pos]['alt'] == '.':
                    confirmed.append( (chrom, pos, None) )
        
        return confirmed
    
    def get_snps(self):
        snps = []
        for chrom in sorted(self.data):
            for pos in sorted(self.data[chrom]):
                if self.data[chrom][pos]['filter'] == 'PASS' and self.data[chrom][pos]['alt'] != '.':
                    snps.append( (chrom, pos, self.data[chrom][pos]['alt']) )
        return snps
    
    def get_ambiguous(self):
        amb = []
        for chrom in sorted(self.data):
            for pos in sorted(self.data[chrom]):
                if self.data[chrom][pos]['filter'] == 'amb':
                    amb.append( (chrom, pos, self.data[chrom][pos]['alt']) )
        return amb
    
    def __len__(self):
        return self.positions
    
    def __str__(self):
        return "VCF <source=%s reference=%s %d info %d filters %d chromosomes %d positions>" % (self.source, self.reference, len(self.info), len(self.filters), len(self.data), self.positions)

def parse_vcf_file(file):
    vcf = VCF(name=os.path.basename(file))
    with open(file, 'rb') as f:
        for line in f:
            if line[0] == '#':
                if line[1] == '#':
                    if 'fileDate' in line:
                        vcf.date = line.strip().split('=')[1]
                    elif 'source' in line:
                        vcf.source = line.strip().split('=')[1]
                    elif 'reference' in line:
                        vcf.reference = line.strip().split('=')[1]
                    elif '##INFO' in line:
                        temp = info_line.match(line)
                        if not temp:
                            print "Invalid info line", line
                            continue
                        (id, number, type, description) = temp.groups()
                        vcf.info[id] = {'Number': number, 'Type': type, 'Description': description}
                    elif '##FILTER' in line:
                        temp = filter_line.match(line)
                        if not temp:
                            print "Invalid filter line", line
                            continue
                        (id, description) = temp.groups()
                        vcf.filters[id] = {'description': description, 'count': 0}
                    else:
                        pass
                        #print "Unknown line!", line
                else:
                    # header def line
                    header = line.strip().split("\t")
                    if header[:8] != ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']:
                        print "Invalid header line!", line
                        return
            else:
                vcf.add(line)
    
    return vcf


def get_overlapping_pos(v1, v2, exact=True):
    if exact:
        return sorted(list(set(v1).intersection(v2)))
    
    # this assumes chrom and pos are sorted...
    overlap = []
    j = 0
    for (chrom, pos, alt) in v1:
        # reached end of v2
        if j >= len(v2):
            break
        # v1 chrom comes before v2 chrom
        if v2[j][0] > chrom:
            continue
        # chrom are == but v1 pos comes before v2 pos
        if v2[j][0] == chrom and v2[j][1] > pos:
            continue
        # v2 chrom comes before v1 chrom
        if v2[j][0] < chrom:
            j += 1
        # v2 chrom == v1 chrom but v2 pos before v1 pos
        elif v2[j][0] == chrom and v2[j][1] < pos:
            j += 1
        # get here only if chrom and pos ==
        else:
            overlap.append((chrom, pos, alt, v2[j][2]))
    
    return overlap



def compare_vcf_files(vcfs):
    # get snps and amb calls for each vcf
    refs = {}
    confirmed = {}
    snps = {}
    ambs = {}
    for vcf in vcfs:
        refs[vcf.name] = vcf.reference
        confirmed[vcf.name] = vcf.get_confirmed()
        snps[vcf.name] = vcf.get_snps()
        ambs[vcf.name] = vcf.get_ambiguous()
    
    # for each pair of vcf
    comps = {}
    for (v1, v2) in itertools.combinations(snps.keys(), 2):
        print "Comparing %s to %s" % (v1, v2)
        if refs[v1] != refs[v2]:
            print "Different references", refs[v1], refs[v2]
            continue
        # get overlapping confirmed positions
        overlap_confirmed = get_overlapping_pos(confirmed[v1], confirmed[v2], exact=True)
        # get identical snps between them
        overlap_snps = get_overlapping_pos(snps[v1], snps[v2], exact=True)
        # also get overlap of amb calls (check for alt alleles)
        # TODO: check exact match... or top match..., or just the set (forget ranking)
        # TODO: use Allele frequencies
        overlap_ambs = get_overlapping_pos(ambs[v1], ambs[v2], exact=False)
        # and finally look for overlap of snps and amb between pair
        overlap_nonref = sorted(get_overlapping_pos(snps[v1], ambs[v2], exact=False)+get_overlapping_pos(ambs[v1], snps[v2], exact=False))

        # look for signals that conflict b/w samples (SNP in one and REF in other)
        conflicts = sorted(get_overlapping_pos(snps[v1], confirmed[v2], exact=False)+get_overlapping_pos(confirmed[v1], snps[v2], exact=False))

        # report % overlap somehow...
        print "Overlapping confirmed reference positions:", len(overlap_confirmed)
        total = len(overlap_snps) + len(overlap_ambs) + len(overlap_nonref)
        print "Total overlapping non-reference positions shared:", total
        print "Exact SNPs overlapping:", len(overlap_snps)
        print "Ambiguous calls overlapping:", len(overlap_ambs)
        print "Non-reference positions shared:", len(overlap_nonref)
        print "Conflicting evidence (SNP in one, REF in other):", len(conflicts)
        comps[(v1, v2)] = (len(overlap_confirmed), len(overlap_snps), len(overlap_ambs), len(overlap_nonref), len(conflicts))
    
    return comps
    

def load_pileups(file):
    """Load straingr pileups"""
    with gzip.open(file) as f:
        pileups = Pileups(cPickle.load(f), name=os.path.basename(file), keepCovered=False)

        return pileups


def easy_compare(s1, s2):
    """Compare two samples from same reference"""
    i = 0
    confirmed = 0
    snps = 0
    ambs = 0
    non_refs = 0
    conflicts = 0
    for scaffold in s1.pileups:
        if scaffold not in s2.pileups:
            continue
        for pos in s1.pileups[scaffold]:
            if pos not in s2.pileups[scaffold]:
                continue # not found in 2
            elif not s1.pileups[scaffold][pos].covered():
                continue # not covered in 1
            elif not s2.pileups[scaffold][pos].covered():
                continue # not covered in 2
            elif s1.pileups[scaffold][pos].confirmed():
                if s2.pileups[scaffold][pos].confirmed():
                    confirmed += 1 # ref in both
                elif s2.pileups[scaffold][pos].base_call():
                    conflicts += 1 # ref in 1, snp in 2
            elif s1.pileups[scaffold][pos].base_call():
                if s2.pileups[scaffold][pos].confirmed():
                    conflicts += 1 # snp in 1, ref in 2
                elif s1.pileups[scaffold][pos].base_call() == s2.pileups[scaffold][pos].base_call():
                    snps += 1 # snp in both and same snp
                else:
                    non_refs += 1 # snp in 1 but amb in 2
            else:
                if s2.pileups[scaffold][pos].base_call():
                    non_refs += 1 # amb in 1, snp in 2
                elif not s1.pileups[scaffold][pos].confirmed():
                    ambs += 1 # amb in both
    

    total = confirmed + snps + amb + non_ref + conflicts
    print "Total positions analyzed:", total
    print "Reference confirmed in both", confirmed, float(confirmed)/total*100, '%'
    print "SNP confirmed in both", snps, float(snps)/total*100, '%'
    print "Ambiguous calls in both", ambs, float(ambs)/total*100, '%'
    print "Other non-reference calls in both", non_refs, float(non_refs)/total*100, '%'
    print "Conflicting evidence between samples", conflicts, float(conflicts)/total*100, '%'

    return (confirmed, snps, ambs, non_refs, conflicts)


# TODO: make some amalgam of sites, a la pan-genome...
def compare_references(s1, s2):
    s1_reads = []
    s2_reads = []

    pileups = {
        'confirmed': [],
        'snps': [],
        'ambs': [],
        'likely_ref_s1': [],
        'likely_ref_s2': [],
        's1_only': [],
        's2_only': [],
        'problematic': [],
        's1_pileups': [],
        's2_pileups': [],
    }

    # ref confirmed in both (same nt)
    confirmed = 0
    # snp confirmed in both (same nt)
    snps = 0
    # amb calls in both
    ambs = 0
    # snp confirmed in s2, but likely ref allele from s1 ref
    likely_ref_s1 = 0
    # snp confirmed in s1, but likely ref allele from s2 ref
    likely_ref_s2 = 0
    # found only in s1
    s1_only = 0
    # found only in s2
    s2_only = 0
    
    # various positions that don't make sense
    problematic = 0

    # already matched from p1
    p2_analyzed = {}
    # already matched from p2
    p1_analyzed = {}

    for read in s1.reads:
        if read not in s2.reads:
            s1_reads.append(read)
    for read in s2.reads:
        if read not in s1.reads:
            s2_reads.append(read)
    
if len(s1_reads) == len(s1.reads) or len(s2_reads) == len(s2.reads):
    print "No overlapping reads between comparitors!"
    return

    for scaffold in s1.pileups:
        for pos in s1.pileups[scaffold]:
            s2_hits = {}
            p1 = s1.pileups[scaffold][pos]
             
            if not p1.covered():
                continue
            for read in p1.reads:
                if read in s1_reads:
                    continue
                read_pos = p1.reads[read][0]
                if read_pos not in s2.reads[read]:
                    # this base did not align in s2 ref
                    continue
                hit = s2.reads[read][read_pos]
                if hit not in s2_hits:
                    s2_hits[hit] = 0
                s2_hits[hit] += 1
            if not s2_hits:
                # didn't find any pileups to match to in s2
                continue
            elif len(s2_hits) == 1:
                # only one pileup matched! this is the one
                hit = s2_hits.keys()[0]
            else:
                hit = max(s2_hits, key = lambda x: s2_hits[x], reverse=True)
                if s2_hits[top] < sum(s2_hits.values())*.5:
                    # there's no majority pileup
                    continue
            
            # got a matching pileup in s2
            if hit in p2_analyzed:
                print "Already found position matching this pileup"
                if s2_hits[hit] > p2_analyzed[hit]:
                    print "This one is better!"
                else:
                    print "Previous pileup was better."

            p2_analyzed[hit] = s2_hits[hit]
            p1_analyzed[(scaffold, pos)] = s2_hits[hit]
            p2 = s2.pileups[hit[0]][hit[1]]                

            if not p2.covered():
                s1_only += 1 # not covered in p2
                pileups['s1_only'].append((p1, p2))
                continue
            if p1.confirmed():
                if p2.confirmed():
                    if p1.refbase == p2.refbase:
                        confirmed += 1 # confirmed ref bases and same
                        pileups['confirmed'].append((p1, p2))
                    else:
                        problematic += 1 # confirmed diff ref bases
                        pileups['problematic'].append((p1, p2))
                elif p2.base_call() == p1.refbase:
                    likely_ref_s1 += 1 # p2 SNP is actually ref base
                    pileups['likely_ref_s1'].append((p1, p2))
                elif p2.base_call():
                    problematic += 1 # p2 SNP but p1 REF but diff SNP
                    pileups['problematic'].append((p1, p2))
                else:
                    likely_ref_s1 += 1 # amb call in p2 but ref p1
            elif p1.base_call():
                if p2.confirmed():
                    if p2.refbase == p1.base_call():
                        likely_ref_s2 += 1 # p1 SNP is p2 ref base
                        pileups['likely_ref_s2'].append((p1, p2))
                    else:
                        problematic += 1 # p1 SNP is not p2 ref base but p2 ref confirmed
                        pileups['problematic'].append((p1, p2))
                elif p2.base_call() == p1.base_call():
                    snps += 1 # both snps and same snp called
                    pileups['snps'].append((p1, p2))
            else:
                if p2.confirmed():
                    likely_ref_s2 += 1 # amb call in p1 but p2 ref
                    pileups['likely_ref_s2'].append((p1, p2))
                elif p2.base_call():
                    problematic += 1 # amb call in p1 but snp in p2
                    pileups['problematic'].append((p1, p2))
                else:
                    ambs += 1 # amb call in both
                    pileups['ambs'].append((p1, p2))
    
    for scaffold in s2.pileups:
        for pos in s2.pileups[scaffold]:
            if (scaffold, pos) in p2_analyzed:
                continue
            s1_hits = {}
            p2 = s2.pileups[scaffold][pos]
            if not p2.covered():
                continue
            for read in p2.reads:
                if read in s2_reads:
                    continue
                read_pos = p2.reads[read][0]
                if read_pos not in s1.reads[read]:
                    # this base did not align in s1 ref
                    continue
                hit = s1.reads[read][read_pos]
                if hit not in s1_hits:
                    s1_hits[hit] = 0
                s1_hits[hit] += 1
            if not s1_hits:
                # didn't find any pileups to match to in s1
                continue
            elif len(s1_hits) == 1:
                # only one pileup matched! this is the one
                hit = s1_hits.keys()[0]
            else:
                hit = max(s1_hits, key = lambda x: s1_hits[x], reverse=True)
                if s1_hits[top] < sum(s1_hits.values())*.5:
                    # there's no majority pileup
                    continue
            
            # got a matching pileup in s1
            if hit in p1_analyzed:
                print "Already found position matching this pileup"
                if s1_hits[hit] > p2_analyzed[hit]:
                    p1_analyzed[hit] = s1_hits[hit]
                    print "This one is better!"
                else:
                    print "Previous pileup was better."

            p1 = s1.pileups[hit[0]][hit[1]]                

            if not p1.covered():
                s2_only += 1 # not covered in p2
                pileups['s2_only'].append((p1, p2))
                continue
            if p2.confirmed():
                if p1.confirmed():
                    if p1.refbase == p2.refbase:
                        confirmed += 1 # confirmed ref bases and same
                        pileups['confirmed'].append((p1, p2))
                    else:
                        problematic += 1 # confirmed diff ref bases
                        pileups['problematic'].append((p1, p2))
                elif p1.base_call() == p2.refbase:
                    likely_ref_s2 += 1 # p1 SNP is actually ref base
                    pileups['likely_ref_s2'].append((p1, p2))
                elif p1.base_call():
                    problematic += 1 # p1 SNP but p1 REF but diff SNP
                    pileups['problematic'].append((p1, p2))
                else:
                    likely_ref_s2 += 1 # amb call in p1 but ref p2
                    pileups['likely_ref_s2'].append((p1, p2))
            elif p2.base_call():
                if p1.confirmed():
                    if p1.refbase == p2.base_call():
                        likely_ref_s1 += 1 # p2 SNP is p1 ref base
                        pileups['likely_ref_s1'].append((p1, p2))
                    else:
                        problematic += 1 # p2 SNP is not p1 ref base but p1 ref confirmed
                        pileups['problematic'].append((p1, p2))
                elif p2.base_call() == p1.base_call():
                    snps += 1 # both snps and same snp called
                    pileups['snps'].append((p1, p2))
            else:
                if p1.confirmed():
                    likely_ref_s1 += 1 # amb call in p2 but p1 ref
                    pileups['likely_ref_s1'].append((p1, p2))
                elif p1.base_call():
                    problematic += 1 # amb call in p2 but snp in p1
                    pileups['problematic'].append((p1, p2))
                else:
                    ambs += 1 # amb call in both
                    pileups['ambs'].append((p1, p2))
    
    s1_pileups = 0
    s2_pileups = 0
    for read in s1_reads:
        for pos in s1_reads[read]:
            hit = s1_reads[read][pos]
            if hit not in p1_analyzed:
                s1_pileups += 1 # pileup not found previously
                pileups['s1_pileups'].append(s1.pileups[hit[0]][hit[1]])
    
    for read in s2_reads:
        for pos in s2_reads[read]:
            hit = s2_reads[read][pos]
            if hit not in p2_analyzed:
                s2_pileups += 1 # pileup not found previously
                pileups['s2_pileups'].append(s2.pileups[hit[0]][hit[1]])


    return (pileups, confirmed, snps, ambs, likely_ref_s1, likely_ref_s2, s1_only, s2_only, problematic, len(s1_reads), len(s2_reads), s1_pileups, s2_pileups)




parser = argparse.ArgumentParser()
parser.add_argument("--verbose", help="increase output verbosity", action="store_true")
parser.add_argument("--references", action='store_true', help="Compare between references (within samples)")
parser.add_argument('out', help='Output results to file')
parser.add_argument("file", nargs='+', help="file from straingr tool")
args = parser.parse_args()


if args.references:
    all_pileups = {}
    for pkl_file in args.file:
        all_pileups[pkl_file] = load_pileups(pkl_file)
    
    with open(args.out, 'wb') as w:
        w.write("Reference1\tReference2\tConfirmed\tSNPs\tAmbiguous\tRef1\tRef2\tRef1Only\tRef2Only\tProblematic\tRef1Reads\tRef2Reads\tRef1Pileups\tRef2Pileups\n")
        for (s1, s2) in itertools.combinations(all_pileups.keys(), 2):
            comparison = compare_references(all_pileups[s1], all_pileups[s2])
            if comparison:
                w.write('%s\t%s\t%s\n' % (s1, s2, [str(x) for x in comparison[1:]]))


else:
    vcfs = []
    for file in args.file:
        vcfs.append(parse_vcf_file(file))

    compare_vcf_files(vcfs)
