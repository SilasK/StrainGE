#!/usr/bin/env python

import argparse
from collections import OrderedDict
import math
import sys
import h5py
import kmertools
import kmerizer

"""
Strain Genome Search Tool (StrainGST)
"""

parser = argparse.ArgumentParser()
parser.add_argument("-o", "--output", help="output text file (default: standard out)")
parser.add_argument("-i", "--iterations", type=int, default=5, help="max strains to look for (default: 5)")
parser.add_argument("-t", "--top", type=int, default=1, help="How many best matches to print (default: 1)")
parser.add_argument("-f", "--minfrac", type=float, default=0.01, help="minimum fraction of original kmers in strain")
parser.add_argument("-s", "--score", type=float, default=0.01, help="minimum score")
parser.add_argument("-e", "--evenness", type=float, default=0.6, help="minimum evenness")
parser.add_argument("pan", help="hdf5 file containing pan genome kmer set")
parser.add_argument("sample", help="Compare similarity of this vs the other strains instead of all vs all")
args = parser.parse_args()

class Sample(kmertools.KmerSet):
    """
    Sample Kmerset
    Initially loaded with full KmerSet from the sample hdf5 file, but it will be reduced to
    kmers in the pan genome set.
    """

    def __init__(self, hdf5file):
        super(Sample, self).__init__()
        self.name = kmertools.nameFromPath(hdf5file)

        print "Loading sample"
        self.hdf5file = hdf5file
        with h5py.File(hdf5file, 'r') as h5:
            self.load_hdf5(h5)

        # keep track of original totalKmers and distinctKmers
        self.totalKmers = self.counts.sum()
        self.distinctKmers = self.kmers.size

        print self.distinctKmers, "distinct kmers,", self.totalKmers, "total kmers in sample"


class PanGenome(kmertools.KmerSet):
    def __init__(self, hdf5file):
        """
        PanGenome Kmerset
        Operations on on a pan genome kmer data file (as generated by the pankmer utility). The pan genome
        kmer file has a top level KmerSet as well as a group containing a KmerSet for each strain in the pan genome.
        """

        super(PanGenome, self).__init__()
        self.hdf5file = hdf5file

        print "Loading pan genome"
        self.h5 = h5py.File(hdf5file, 'r')
        self.load_hdf5(self.h5)

        # Strains are groups within hdf5 file
        self.strainNames = [name for name in self.h5.keys() if isinstance(self.h5[name], h5py.Group)]
        print len(self.strainNames), "strains,", self.kmers.size, "kmers in pan genome"

        # we'll use this as a lookup for strain-specific KmerSets (filled out on first iteration)
        self.strainCache = {}
        # leave h5 file open, as we'll load the strain-specific KmerSets from it.

    def loadStrain(self, name):
        """
        Load a strain KmerSet. If it's already in our cache, use that, else load from hdf5 file.
        :param name: name of strain (name of group in hdf5)
        :return: strin KmerSet
        """

        if name in self.strainCache:
            return self.strainCache[name]
        else:
            strain = Strain(self, name)
            self.strainCache[name] = strain
            return strain

    def scoreSample(self, sample, outFile=None):
        """
        Find the strains in a sample
        :param sample: Sample object to score
        :param outFile: output file in which to store a table of metrics
        :return: found strains
        """

        # Reduce the sample KmerSet to its intersection with the PanGenome to free up memory and speed things up.
        s = sample.intersect(self.kmers)
        sample.kmers = s.kmers
        sample.counts = s.counts

        # Metrics for Sample kmers in pan genome
        samplePanKmers = sample.counts.sum()
        samplePanKcov = float(samplePanKmers) / float(sample.kmers.size)
        samplePanPct = samplePanKmers * 100.0 / sample.totalKmers
        print "%d pan kmers in sample (%.2f%%)" % (samplePanKmers, samplePanPct)

        if outFile:
            # Print sample-wide metrics to output file
            tabout(("sample", "totalkmers", "distinct", "pkmers", "pkcov", "pan%"), outFile)
            tabout((sample.name, sample.totalKmers, sample.distinctKmers, sample.kmers.size,
                    round(samplePanKcov, 3), round(samplePanPct, 3)), outFile)

        # Excludes will contain kmers removed from consideration because they were in a found strain
        excludes = None
        winners = []

        for i in xrange(args.iterations):

            # If we're just starting, print tabular header for strain metrics
            if i == 0:
                r = Result()
                tabout(r.header(human=True))
                if outFile:
                    tabout(r.header(human=False), outFile)

            # Score all strains and sort results by score
            results = map(lambda s: self.scoreStrain(s, sample, excludes), self.strainNames)
            results.sort(lambda a, b: cmp(b.score(), a.score()))

            winner = results[0]
            # if best score isn't good enough, we're done
            if winner.score() < args.score:
                break

            # Print tabular output stats for winning strain
            for t in xrange(args.top):
                tabout(results[t].format(i, human=True))
                if outFile:
                    tabout(results[t].format(i, human=False), outFile)

            winningStrain = self.loadStrain(winner["strain"])
            winners.append(winningStrain)

            # Exclude kmers from winning strain from sample (and from each strain next iteration)
            excludes = winningStrain.kmers
            sample.exclude(excludes)

        return winners

    def scoreStrain(self, strainName, sample, excludes=None):
        """
        Load a strain and score it against sample, optionally excluding an array of kmers
        :param strainName: strain name (name of group in PanGenome hdf5 file)
        :param sample: Sample object
        :param excludes: numpy array of kmers
        :return:
        """

        strain = self.loadStrain(strainName)
        return strain.scoreSample(sample, excludes)


class Strain(kmertools.KmerSet):
    def __init__(self, pan, name):
        """
        Strain KmerSet object
        Initially contains full strain Kmset, but that might be reduced by excluded kmers.
        :param pan: PanGenome object
        :param name: strain name
        """
        super(Strain, self).__init__()
        self.name = name
        self.pan = pan
        self.load_hdf5(pan.h5[name])
        self.distinctKmers = self.kmers.size
        self.totalKmers = self.counts.sum()

    def scoreSample(self, sample, excludes = None):
        """
        Score this strain within a Sample, excluding any provided kmers from consideration
        :param sample: Sample object
        :param excludes: numpy array of kmers to exclude (will be removed from this KmerSet!)
        :return:
        """

        # Remove excluded kmers from our set
        if excludes is not None:
            self.exclude(excludes)

        # Start to collect result metrics
        metrics = {"strain": self.name,
                   # Genomic distinct kmers
                   "gkmers": self.distinctKmers,
                   # Kmers under consideration this iteration (after excdlued kmers have been removed)
                   "ikmers": self.kmers.size,
                   # Sample kmers under consideration
                   "skmers": sample.kmers.size}

        # If we don't have enough kmers left, quit now
        if self.kmers.size < args.minfrac * self.distinctKmers:
            return Result(metrics)

        # how often each strain kmer occurs in PanGenome
        strainPanCounts = kmerizer.intersect_counts(self.pan.kmers, self.pan.counts, self.kmers)

        # distinct kmers from sample in this strain
        kmers = kmerizer.intersect(self.kmers, sample.kmers)

        # if none, quit now
        if kmers.size == 0:
            return Result(metrics)

        # how many times each occurred in this strain
        counts = kmerizer.intersect_counts(self.kmers, self.counts, kmers)
        # how many times each strain kmer occurred in pan genome (for weighting)
        panCounts = kmerizer.intersect_counts(self.kmers, strainPanCounts, kmers)
        # how many times did each kmers occur in sample?
        sampleCounts = kmerizer.intersect_counts(sample.kmers, sample.counts, kmers)
        sampleCount = sampleCounts.sum()

        # Compute metrics
        # what fraction of the distinct strain kmers are in the sample?
        covered = float(kmers.size) / float(self.kmers.size)
        # for each distinct kmer, how many times did it occur in the sample relative to the strain?
        kmerCoverage = float(sampleCount) / float(sampleCounts.size)
        # mean genome coverage from all my kmers
        genomeCoverage = float(sampleCount) / float(self.counts.sum())

        # converse of covered: what fraction of pan genome sample kmers are accounted for by this sample?
        accounted = float(kmers.size) / float(sample.kmers.size)
        # Lander-Waterman estimate of percentage covered if randomly distributed across genome
        estCovered = 1.0 - math.exp(-genomeCoverage)
        # measure of evenness of coverage
        evenness = covered / estCovered

        # Weight each of my kmers by inverse of times it occurs in pan genome relative to this genome
        strainWeights = self.counts * (1.0 / strainPanCounts)
        strainTotalWeight = strainWeights.sum()

        # Weight of each sample kmer
        sampleWeights = counts * (1.0 / panCounts)
        sampleTotalWeight = (sampleCounts * sampleWeights).sum()

        # Weighted genome coverage
        weightedCoverage = sampleTotalWeight / strainTotalWeight
        # Specificity is a measure of how specific the sample kmers are to this strain. If they are randomly
        # sampled, this should be close to 1. A low number indicates that the sample kmers that hit this
        # strain also tend to be found in other strains. A high number indicates that more kmers specific to this
        # strain are found that would be exected from random sampling, e.g., maybe the sample only contains a
        # chunk of this genome.
        specificity = weightedCoverage / genomeCoverage

        # original panstrain simple scoring metric
        score = covered * evenness * accounted
        # add in specificity component (best match should be close to 1.0, higher or lower is worse)
        weightedScore = score * min(specificity, 1.0 / specificity)

        # populate result metrics and return
        metrics["cov"] = covered
        metrics["kcov"] = kmerCoverage
        metrics["gcov"] = genomeCoverage
        metrics["acct"] = accounted
        metrics["even"] = evenness
        metrics["wcov"] = weightedCoverage
        metrics["spec"] = specificity
        metrics["score0"] = score
        metrics["score"] = weightedScore

        return Result(metrics)


class Result:
    def __init__(self, metrics=None):
        """
        Result object for processing result metrics
        :param metrics: dict of scoring metrics
        """
        self.metrics = metrics
        # we use this padded format for strain names in console log
        self.humanReadableFormat = "%-32s"

    def score(self):
        """
        Compute score from metrics, filtering by thresholds
        :return: filtered score
        """
        if not self.metrics:
            return 0
        s = self["score"]
        return s if s >= args.score and self["even"] >= args.evenness else 0


    def header(self, human=False):
        """
        Print tabular header
        :param human: True if intended for human parsing
        :return: list of table column headers
        """
        return [self.humanReadableFormat % k if k == "strain" and human else k for k in Result.resultFormats.keys()]

    def format(self, iteration, human=False):
        """
        Return list of formatted metrics
        :param iteration: iteration number to be included
        :param human: True if intended for human parsing
        :return: list of metric strings for columns of table
        """
        self.metrics["i"] = iteration
        values = [self.formatValue(key, human) for key in Result.resultFormats]
        return values

    def formatValue(self, thing, human=False):
        """
        Format value using resultFormats
        :param thing: metrics name
        :param human: True if for human reading
        :return: formatted string of metric value
        """
        fmt = self.humanReadableFormat if thing == "strain" and human else Result.resultFormats[thing]
        return fmt % (self[thing],)

    def __getitem__(self, item):
        """
        Allow indexing a la dict, returning 0 for non-existant metrics
        :param item: item (metric name)
        :return: item value
        """
        return self.metrics.get(item, 0) if self.metrics else None

    def __repr__(self):
        return str(self.metrics)

    # Format for each metric, in order we want them presented
    resultFormats = OrderedDict([("i", "%d"),
                                 ("strain", "%s"),
                                 ("gkmers", "%d"),
                                 ("ikmers", "%d"),
                                 ("skmers", "%d"),
                                 ("cov", "%.3f"),
                                 ("kcov", "%.3f"),
                                 ("gcov", "%.3f"),
                                 ("acct", "%.3f"),
                                 ("even", "%.3f"),
                                 ("score0", "%.3f"),
                                 ("spec", "%.3f"),
                                 ("wcov", "%.3f"),
                                 ("score", "%.3f"),
                                 ])


def tabout(things, file=sys.stdout):
    """
    Print tab-separated sequence of things to line in file
    :param things: sequence of things
    :param file: output file
    """
    print >>file, "\t".join([str(x) for x in things])
    file.flush()


##################
##### MAIN
##################

outFile = open(args.output, 'w') if args.output else None
pan = PanGenome(args.pan)
sample = Sample(args.sample)
pan.scoreSample(sample, outFile)
if outFile:
    outFile.close()
