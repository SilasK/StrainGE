#!/usr/bin/env python
import os
import sys
import argparse
from collections import OrderedDict
import math
from multiprocessing import Pool
import numpy as np
import kmertools
import kmerizer
import h5py


parser = argparse.ArgumentParser()
parser.add_argument("-f", "--fingerprint", help="use minhash fingerprint instead of full kmer set to build graph",
                    action="store_true")
parser.add_argument("-v", "--verbose", action='store_true', help="More output")
parser.add_argument("-K", type=int, default=kmertools.DEFAULT_K, help="Kmer size (default: %d)" % (kmertools.DEFAULT_K))
parser.add_argument("-o", "--output", help="output text file (default: standard out)")
parser.add_argument("-i", "--iterations", type=int, default=5, help="max strains to look for (default: 5)")
parser.add_argument("-t", "--top", type=int, default=1, help="How many best matches to print (default: 1)")
parser.add_argument("-m", "--minfrac", type=float, default=0.05, help="minimum fraction of original kmers in strain")
parser.add_argument("-s", "--score", type=float, default=0.005, help="minimum score")
parser.add_argument("-e", "--evenness", type=float, default=0.6, help="minimum evenness")
parser.add_argument("-S", "--scoring", choices=("default", "weighted"), default="default", help="scoring algorithm")
#parser.add_argument("-r", "--readlength", type=int, default=101, help="Read length (for better coverage estimates, default: 101)")
parser.add_argument("-p", "--threads", type=int, default=1, help="Parallel threads (implies --cache)")
parser.add_argument("pan", help="hdf5 file containing pan genome kmer set")
parser.add_argument("sample", help="Compare similarity of this vs the other strains instead of all vs all")
args = parser.parse_args()

strainKmerSets = {}

class Sample(kmertools.KmerSet):
    def __init__(self, hdf5file):
        self.name = kmertools.nameFromPath(hdf5file)
        print "Loading sample"
        self.hdf5file = hdf5file
        h5 = h5py.File(hdf5file, 'r')
        self.load_hdf5(h5)
        self.totalCount = self.counts.sum()
        print self.kmers.size, "distinct kmers,", self.totalCount, "total kmers in sample"


class PanGenome(kmertools.KmerSet):
    def __init__(self, hdf5file):
        self.hdf5file = hdf5file
        print "Loading pan genome"
        self.h5 = h5py.File(hdf5file, 'r')
        self.load_hdf5(self.h5)
        # Strains are groups within hdf5 file
        self.strainNames = [name for name in self.h5.keys() if isinstance(self.h5[name], h5py.Group)]
        print len(self.strainNames), "strains,", self.kmers.size, "kmers in pan genome"
        self.strainCache = {}

    def loadStrain(self, name):
        if name in self.strainCache:
            return self.strainCache[name]
        else:
            strain = Strain(self, name)
            self.strainCache[name] = strain
            return strain

    def scoreSample(self, sample):
        s = sample.intersect(self.kmers)
        sample.kmers = s.kmers
        sample.counts = s.counts

        excludes = None

        for i in xrange(args.iterations):
            print "Iteration", i, sample.kmers.size, "pan kmers in sample"
            results = map(lambda s: self.scoreStrain(s, sample, excludes), self.strainNames)
            top = self.processResults(results)

            if not top:
                return

            for t in xrange(args.top):
                print top[t]

            winnerName = top[0]["strainname"]
            winner = self.loadStrain(winnerName)
            excludes = winner.kmers
            sample.exclude(excludes)



    def scoreStrain(self, strainName, sample, excludes=None):
        strain = self.loadStrain(strainName)
        return strain.scoreSample(sample, excludes)

    def processResults(self, results):
        results = list(filter(lambda r: r and r["score"] >= args.score and r["even"] >= args.evenness, results))
        results.sort(lambda a, b: cmp(b["score"], a["score"]))
        return results


class Strain(kmertools.KmerSet):
    def __init__(self, pan, name):
        self.name = name
        self.pan = pan
        self.load_hdf5(pan.h5[name])
        self.distinctKmers = self.kmers.size
        self.totalKmers = self.counts.sum()

    def scoreSample(self, sample, excludes = None):
        if excludes is not None:
            self.exclude(excludes)

        if self.kmers.size < args.minfrac * self.distinctKmers:
            print self.name, "not enough kmers:", self.kmers.size
            return None

        strainPanCounts = kmerizer.intersect_counts(self.pan.kmers, self.pan.counts, self.kmers)

        # distinct kmers in this strain and sample
        kmers = kmerizer.intersect(self.kmers, sample.kmers)
        # how many times each occurred in this strain
        counts = kmerizer.intersect_counts(self.kmers, self.counts, kmers)
        # how many times each strain kmer occurred in pan genome (for weighting)
        panCounts = kmerizer.intersect_counts(self.kmers, strainPanCounts, kmers)
        # how many times did each common kmers occurred in sample?
        sampleCounts = kmerizer.intersect_counts(sample.kmers, sample.counts, kmers)
        sampleCount = sampleCounts.sum()

        # Compute metrics
        # what fraction of the distinct kmers are in the sample?
        covered = float(kmers.size) / float(self.kmers.size)
        # for each distinct kmer in common, how many times did it occur in the sample relative to the strain?
        kmerCoverage = float(sampleCount) / float(counts.sum())
        # mean genome coverage from all my kmers
        genomeCoverage = float(sampleCount) / float(self.counts.sum())

        # converse of covered: what fraction of pan genome sample kmers are accounted for by this sample?
        accounted = float(kmers.size) / float(sample.kmers.size)
        # Lander-Waterman estimate of percentage covered if randomly distributed across genome
        estCovered = 1.0 - math.exp(-genomeCoverage)
        # measure of evenness of coverage
        evenness = covered / estCovered

        strainWeights = self.counts * (1.0 / strainPanCounts)
        strainTotalWeight = strainWeights.sum()

        sampleWeights = counts * (1.0 / panCounts)
        weight = (sampleCounts * sampleWeights).sum()

        weightedCoverage = weight / strainTotalWeight
        specificity = weightedCoverage / genomeCoverage

        score = covered * evenness * accounted
        weightedScore = score * min(specificity, 1.0 / specificity)

        results = {"strainname": self.name,
                   "gkmers": self.totalKmers,
                   "xkmers": self.kmers.size,
                   "cov": covered,
                   "kcov": kmerCoverage,
                   "gcov": genomeCoverage,
                   "acct": accounted,
                   "even": evenness,
                   "wcov": weightedCoverage,
                   "spec": specificity,
                   "score": score,
                   "wscore": weightedScore}

        return results


def tabout(things, file=sys.stdout):
    """
    Print tab-separated sequence of things to line in file
    :param things: sequence of things
    :param file: output file
    """
    print >>file, "\t".join([str(x) for x in things])
    file.flush()

resultFormats = OrderedDict([("i", "%d"),
                             ("strainname", "%s"),
                             ("gkmers", "%d"),
                             ("xkmers", "%d"),
                             ("cov", "%.3f"),
                             ("kcov", "%.2f"),
                             ("gcov", "%.2f"),
                             ("acct", "%.3f"),
                             ("even", "%.3f"),
                             ("spec", "%.2f"),
                             ("score", "%.3f")])


pan = PanGenome(args.pan)
sample = Sample(args.sample)
pan.scoreSample(sample)
