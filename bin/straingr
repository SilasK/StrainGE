#!/usr/bin/env python
"""StrainGR"""

import argparse
import math
import sys
from datetime import date
import numpy as np
import pysam
import kmertools



parser = argparse.ArgumentParser(description="""
Strain Genome Recovery (StrainGR) Tool
""")
parser.add_argument("--output", "-o",
                    help="output file")
parser.add_argument("--verbose", "-v",
                    help="increase output verbosity", action="store_true")
parser.add_argument("--minqual", "-q", type=int, default=5,
                    help='minimum base Quality score to consider')
parser.add_argument("--minmq", "-m", type=int, default=5,
                    help='minimum read Mapping quality score to consider')
parser.add_argument("--minconfirm", "-c", type=int, default=50,
                    help="minimum Pileup quality sum to confirm reference or SNP (with minfrac)")
parser.add_argument("--mingap", "-g", type=int, default=2000,
                    help="minimum contiguous uncovered (Gap) region to flag")
parser.add_argument("--minfrac", "-f", type=float, default=0.1,
                    help="minimum fraction of evidence to confirm presence (with minconfirm)")
parser.add_argument("--log", "-l",
                    help="log file")
parser.add_argument("reference",
                    help="reference FASTA file")
parser.add_argument("bam", nargs='+',
                    help="bam file of reads aligned to reference (sorted & indexed)")
args = parser.parse_args()

logfile = open(args.log, 'w') if args.log else sys.stdout


bases = set(list("ACGT"))




class Genome:
    def __init__(self, fasta):
        self.scaffolds = [Scaffold(scaffold.name, scaffold.seq.upper()) for scaffold in kmertools.openSeqFile(fasta)]
        self.length = sum([s.length for s in self.scaffolds])
        # These are filled out after allele calling
        self.refmask = None
        self.coverage = None
        self.highCoverage = None
        self.strong = None
        self.weak = None
        self.summaryStats = None

        print >> logfile, "Reference has", len(self.scaffolds), "scaffolds containing", self.length, "bases"

    def process(self, bam):
        with pysam.AlignmentFile(bamfile, "rb") as bam:
            for s in self.scaffolds:
                s.makePileups(bam)

        self.refmask = np.concatenate([s.refmask for s in self.scaffolds])
        self.coverage = np.concatenate([s.coverage for s in self.scaffolds])
        meanCoverage = self.coverage.sum() / float(self.length)
        highCutoff = self.poissonCutoff(meanCoverage)
        print >>logfile, "Total length=%d coverage=%.2f cutoff=%d" % (self.length, meanCoverage, highCutoff),

        nonzero = self.coverage[self.coverage > 0]
        nonzeroCoverage = float(nonzero.sum()) / float(nonzero.size)
        highCutoff = self.poissonCutoff(nonzeroCoverage)
        print >>logfile, "nonzero=%d nzcoverage=%.2f cutoff=%d" % (nonzero.size, nonzeroCoverage, highCutoff),

        nice = nonzero[nonzero < highCutoff]
        niceCoverage = float(nice.sum()) / float(nice.size)
        print >>logfile, "nice=%d nicecoverage=%.2f" % (nice.size, niceCoverage)

        for s in self.scaffolds:
            s.callAlleles(highCutoff)

        self.highCoverage = np.concatenate([s.highCoverage for s in self.scaffolds])
        self.strong = np.concatenate([s.strong for s in self.scaffolds])
        self.weak = np.concatenate([s.weak for s in self.scaffolds])

        self.summaryStats = CallStats(self.length, self.refmask, self.coverage, self.strong, self.highCoverage)
        print >>logfile, "TOTAL",
        self.summaryStats.log()

        if args.output:
            with open(args.output, 'w') as outfile:
                self.summaryStats.tabular(outfile, "TOTAL", True)
                for s in self.scaffolds:
                    s.summaryStats.tabular(outfile, s.name)
                self.summaryStats.tabular(outfile, "TOTAL")

    def poissonCutoff(self, mean, cutoff = 0.9999999):
        """Calculate the Poisson CDF and find where it reaches the cutoff"""
        i = 0
        ifact = 1.0
        expmean = math.exp(-mean)
        cdf = 0.0
        while cdf < cutoff:
            cdf += expmean * math.pow(mean, i) / ifact
            i += 1
            ifact *= i
        return i - 1


class Scaffold:
    def __init__(self, name, sequence):
        self.name = name
        self.sequence = sequence
        self.length = len(sequence)
        self.pileups = np.array([Pileup(base) for base in sequence], dtype=np.dtype(object))
        # pileup stats
        self.refmask = np.zeros(self.length, dtype=np.uint8)
        self.coverage = np.zeros(self.length, dtype=np.uint32)
        # allele call stats
        self.strong = np.zeros(self.length, dtype=np.uint8)
        self.weak = np.zeros(self.length, dtype=np.uint8)
        # allele call arrays computed here
        self.highCoverage = None
        self.summaryStats = None

    def makePileups(self, bam):
        print >>logfile, "Processing", self.name, "length=%d" % self.length,
        logfile.flush()

        for column in bam.pileup(self.name):
            refpos = column.reference_pos
            self.pileups[refpos].add_reads(column.pileups)

        for i in xrange(self.length):
            p = self.pileups[i]
            self.coverage[i] = p.depth()
            self.refmask[i] = p.refmask

        self.meancoverage = float(self.coverage.sum()) / float(self.length)

        print >>logfile, "coverage=%.2f" %self.meancoverage
        logfile.flush()

    def callAlleles(self, highCutoff):
        print >>logfile, "Calling", self.name,
        logfile.flush()

        self.highCoverage = self.coverage > highCutoff

        for i in xrange(self.length):
            if self.coverage[i] and not self.highCoverage[i]:
                p = self.pileups[i]
                p.callAlleles()
                self.strong[i] = p.strong
                self.weak[i] = p.weak

        self.summaryStats = CallStats(self.length, self.refmask, self.coverage, self.strong, self.highCoverage)
        self.summaryStats.log()


    def process(self, bam):
        """Scan the pileups for each locus in the scaffold"""

        print >>logfile, "Processing", self.name, self
        last_covered = -1
        goodcoverage = 0

        for column in bam.pileup(self.name):
            refpos = column.reference_pos
            pileup = Pileup(self.sequence[refpos])
            pileup.add_reads(column.pileups)
            self.pileups[refpos] = pileup

            if args.verbose:
                refbase = self.sequence[refpos]
                print >> logfile, "Ref:", column.reference_name, refpos, refbase, column.nsegments
            goodcoverage += pileup.depth()
            if pileup.covered():
                covered += 1
                if pileup.strong():
                    confirmed += 1
                else:
                    # keep read info for covered, non-ref alleles
                    # self.insert_into_db(pileup)
                    if pileup.base_call():
                        snps += 1
                if refpos - last_covered > args.min_gap:
                    gap = (last_covered + 1, refpos - last_covered)
                    print >> logfile, "Coverage gap:", gap[0], gap[1]
                    gaps.append(gap)
                last_covered = refpos
            else:
                if pileup.unmappable():
                    unmapped += 1
                    # not a real gap, just can't map to this region
                    if refpos - last_covered > args.min_gap:
                        gap = (last_covered + 1, refpos - last_covered)
                        print >> logfile, "Coverage gap:", gap[0], gap[1]
                        gaps.append(gap)
                    last_covered = refpos
                    # if keep:
                    # keep all pileups anyway
                    # self.insert_into_db(pileup)

            # del pileup.reads

            if args.verbose:
                print >> logfile, pileup, pileup.strong()

        coverage = float(goodcoverage) / float(length)
        mixed = covered - (confirmed + snps)

        print >> logfile, "good coverage: %.1fx" % (coverage,)
        print >> logfile, "covered: %d %.1f%%" % (covered, pct(covered, length))
        print >> logfile, "confirmed: %d %.2f%%" % (confirmed, pct(confirmed, covered))
        print >> logfile, "snps: %d %.3f%%" % (snps, pct(snps, covered))
        if snps > 0:
            snp_rate = "%.0f" % (float(covered) / float(snps))
            print >> logfile, "snp rate:", snp_rate
        else:
            snp_rate = ""
        print >> logfile, "mixed: %d %.3f%%" % (mixed, pct(mixed, covered))
        if mixed > 0:
            mixed_rate = float(covered) / float(mixed)
            if mixed_rate > 0:
                mixed_quality = math.log10(mixed_rate) * 10.0
            else:
                mixed_quality = 0
            mixed_rate = "%.0f" % (mixed_rate)
            print >> logfile, "mixed rate: %s Q%.0f" % (mixed_rate, mixed_quality)
        else:
            mixed_rate = ""
            mixed_quality = 0
        gap_total = sum([g[1] for g in gaps])
        print >> logfile, "gaps:", len(gaps), "totaling", gap_total
        print >> logfile, "unmapped: %d %.1f%%" % (unmapped, pct(unmapped, length))


class Pileup:
    """
    Class to process pileup information; that is,
    all the alignment information corresponding
    to a given reference coordinate.
    """

    # bases and their indicies (plus I for insertion, D for deletion)
    BASES = "ACGTID"
    A = 0
    C = 1
    G = 2
    T = 3
    I = 4
    D = 5
    ALLELES = len(BASES)
    ALLELE_MASKS = 1 << np.arange(ALLELES, dtype=np.int32)


    def __init__(self, refbase):
        """
        :param scaffold: reference sequence
        :param pos: coordinate in reference (0-based)
        :param pileup_reads: pileup objects from pysam
        """

        # first dimension is count, qualsum
        self.alleles = np.zeros((2, 6), dtype=np.int32)
        # index into allele array for reference base
        self.refmask = (1 << Pileup.BASES.find(refbase)) if refbase != "N" else 0
        self.bad = 0
        self.lowmq = 0
        self.strong = 0
        self.weak = 0

    def add_reads(self, pileup_reads):
        """Add a bunch of pysam.PileupRead objects to this pileup"""
        for read in pileup_reads:
            self.add_read(read)

    def add_read(self, read):
        """Add a pysam.PileupRead object to this pileup"""
        alignment = read.alignment

        # if this is a paired read, make sure the pairs are properly aligned
        if (not alignment.is_paired) or (not alignment.is_proper_pair):
            self.bad += 1
            return

        # restrict ourselves to full-length alignments (not clipped)
        if alignment.query_alignment_length != alignment.query_length:
            # alignment is clipped
            self.bad += 1
            return

        # check that inferred insert size is at least read length
        tlen = alignment.template_length
        if abs(tlen) < alignment.query_length:
            self.bad += 1
            return

        # get base quality (note this is next base if deletion)
        pos = read.query_position_or_next
        qual = alignment.query_qualities[pos]
        if qual < args.minqual:
            self.bad += 1
            return

        # check for decent mapping quality
        mq = alignment.mapping_quality
        if mq < args.minmq:
            self.lowmq += 1
            return

        if read.indel:
            if read.is_del:
                baseIndex = Pileup.D
                # if the base isn't there, base qual doesn't make sense
                qual = mq
            else:
                baseIndex = Pileup.I
        else:
            # base call must be real base (e.g., not N)
            base = alignment.query_sequence[pos]
            baseIndex = Pileup.BASES.find(base)
            if baseIndex < 0:
                self.bad += 1
                return

        # We're good! Update the pileup stats...
        q = min(qual, mq)
        self.alleles[0, baseIndex] += 1
        self.alleles[1, baseIndex] += q

    def depth(self):
        """Sum of all quality evidence"""
        return self.alleles[0].sum()

    def qual_total(self):
        """Sum of all quality evidence"""
        return self.alleles[1].sum()

    def total_depth(self):
        return self.depth() + self.bad

    def covered(self):
        """Does this pileup have enough data to consider this locus covered?"""
        return self.qual_total() >= args.minconfirm

    def poormq(self):
        """Good quality sequence, but can't be mapped"""
        return self.lowmq > (self.total_depth())

    def ref_qual(self):
        return self.alleles[1, self.refindex]

    def ref_fraction(self):
        """Fraction of evidence which supports reference base"""
        return float(self.ref_qual()) / float(self.qual_total())

    def confirmed(self):
        """Does this pileup confirm the reference?"""
        rq = self.ref_qual()
        return rq >= args.minconfirm and \
               (rq == self.qual_total() or self.ref_fraction() > args.consensus)

    def callAlleles(self):
        minconfirm = args.minconfirm
        minfrac = args.minfrac

        quals = self.alleles[1]
        qualsum = float(self.qual_total())
        qualfraction = quals / qualsum

        # Any alleles which have any evidence at all
        evidence = quals > 0
        self.weak = (evidence * Pileup.ALLELE_MASKS).sum()

        # Alleles with sufficient evidence to confirm
        confirmed = np.logical_and(quals > minconfirm, qualfraction > minfrac)
        self.strong = (confirmed * Pileup.ALLELE_MASKS).sum()

        if args.verbose and self.strong and self.refmask != self.strong:
            print self.refmask, self.alleles[0], self.alleles[1], qualfraction, self.weak, self.strong
        return


class CallStats:
    FIELDS = (("length", "%d"), ("coverage", "%.2f"), ("covered", "%d"), ("coveredPct", "%.2f"), ("confirmed", "%d"), \
              ("confirmedPct", "%.2f"), ("snps", "%d"), ("snpPct", "%.2f"), ("multi", "%d"), ("multiPct", "%.2f"), \
              ("high", "%d"), ("highPct", "%.2f"))
    #tab_line = "{ref}\t{bam}\t{chrom}\t{length:d}\t{goodcov:.2f}\t{covered:d}\t{pcovered:.1f}\t{confirmed:d}\t{pconfirmed:.2f}\t{snps:d}\t{psnps:.2f}\t{snprate}\t{mixed:d}\t{pmixed:.2f}\t{mixedrate}\t{mixedquality:.0f}\t{gaps:d}\t{gaptotal:d}\t{unmapped:d}\t{highcov:d}\t{highthresh:d}\n"

    def __init__(self, length, refmask, coverage, strong, high):
        confirmed = (strong & refmask)
        snps = (strong & ~refmask)
        multi = (strong & (strong - 1))
        self.length = length
        self.covered = np.count_nonzero(strong)
        self.coveredPct = pct(self.covered, length)
        self.coverage = float(coverage.sum()) / float(length)
        self.confirmed = np.count_nonzero(confirmed)
        self.confirmedPct = pct(self.confirmed, self.covered)
        self.snps = np.count_nonzero(snps)
        self.snpPct = pct(self.snps, self.covered)
        self.multi = np.count_nonzero(multi)
        self.multiPct = pct(self.multi, self.snps)
        self.high = np.count_nonzero(high)
        self.highPct = pct(self.high, length)

        self.values = (self.length, self.coverage, self.covered, self.coveredPct, self.confirmed, self.confirmedPct,
                       self.snps, self.snpPct, self.multi, self.multiPct, self.high, self.highPct)

    def log(self):
        s = ' '.join([(field[0] + '=' + field[1]) % value for field, value in zip(CallStats.FIELDS, self.values)])
        print >>logfile, s
        logfile.flush()

    def tabular(self, out, name, header=False):
        if header:
            print >>out, "\t".join(["name"] + [field for field, fmt in CallStats.FIELDS])
        else:
            print >>out, "\t".join([name] + [ff[1] % value for ff, value in zip(CallStats.FIELDS, self.values)])


def pct(numerator, denominator, precision=None):
    """Makes into a percent, avoiding division by zero"""
    if numerator > 0 and denominator > 0:
        value = (100.0 * numerator) / denominator
    else:
        value = 0.0
    if precision is not None:
        value = round(value, precision)
    return value

##################################
### Main
##################################

print >>logfile, "Loading reference genome"
logfile.flush()
reference = Genome(args.reference)

for bamfile in args.bam:
    reference.process(bamfile)


######## ARCHIVE ##########

#
# vcf_header = \
#     """##fileformat=VCFv4.0
#     ##fileDate={date}
#     ##source=StrainGR
#     ##reference={ref}
#     ##INFO=<ID=DP,Number=1,Type=Integer,Description="Total Depth">
#     ##INFO=<ID=RF,Number=1,Type=Float,Description="Reference Fraction">
#     ##INFO=<ID=BQ,Number=1,Type=Integer,Description="RMS base quality">
#     ##INFO=<ID=MQ,Number=1,Type=Integer,Description="RMS mapping quality">
#     ##INFO=<ID=AF,Number=.,Type=Float,Description="Allele Frequency">
#     ##INFO=<ID=SBQ,Number=.,Type=Integer,Description="SNP base quality">
#     ##INFO=<ID=SMQ,Number=.,Type=Integer,Description="SNP mapping quality">
#     ##FILTER=<ID=cv,Description="Coverage too low">
#     ##FILTER=<ID=hc,Description="Coverage abnormally high">
#     ##FILTER=<ID=amb,Description="Ambiguous SNP call">
#     ##FILTER=<ID=um,Description="Poor mapping quality position">
#     ##FILTER=<ID=del,Description="Deletion at position">
#     #CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO
#     """
#
# vcf_row_string = "{CHROM}\t{POS:d}\t{ID}\t{REF}\t{ALT}\t{QUAL:.0f}\t{FILTER}\tDP={DP:d};RF={RF:g};BQ={BQ:.0f};MQ={MQ:.0f}"
#
#
# def vcf_row(CHROM, POS, ID, REF, ALT, QUAL, FILTER, DP, RF, BQ, MQ, AF=None, SBQ=None, SMQ=None):
#     string = vcf_row_string.format(CHROM=CHROM, POS=POS, ID=ID, REF=REF, ALT=ALT, QUAL=QUAL, FILTER=FILTER, DP=DP,
#                                    RF=RF, BQ=BQ, MQ=MQ)
#     if AF:
#         string += ";AF={}".format(AF)
#     if SBQ:
#         string += ";SBQ={}".format(SBQ)
#     if SMQ:
#         string += ";SMQ={}".format(SMQ)
#
#     return string + "\n"
#
#
# def write_vcf(pileups, output=None, date=date.today(), reference=None):
#     """Write SNPs to a VCF file"""
#     with open(output, 'wb') as w:
#         w.write(vcf_header.format(date=date, ref=reference))
#         # for pileup in pileups:
#         for scaffold in pileups.pileups:
#             for refpos in pileups.pileups[scaffold]:
#                 pileup = pileups.pileups[scaffold][refpos]
#                 af = ''
#                 sbq = ''
#                 smq = ''
#                 ALT = '.'
#
#                 # start with qual as ref
#                 if pileup.ref_count:
#                     QUAL = np.sqrt(float(pileup.ref_qual_ss) / pileup.ref_count)
#                 else:
#                     QUAL = 0
#
#                 # higher pileup than expected by random chance
#                 if pileup.hc:
#                     FILTER = "hc"
#
#                 # not enough reads to say anything
#                 elif not pileup.covered():
#                     # due to not being mappable
#                     if pileup.poormq():
#                         FILTER = 'um'
#                     # just not covered enough
#                     else:
#                         FILTER = "cv"
#
#                 # reference has been confirmed
#                 elif pileup.confirmed():
#                     FILTER = "PASS"
#
#                 # reference not confirmed and there are other alleles
#                 elif pileup.others:
#                     snp = pileup.base_call()
#
#                     # confirmed a snp
#                     if snp:
#                         QUAL = np.sqrt(float(pileup.others[snp][1]) / pileup.others[snp][0])
#                         FILTER = "PASS"
#                         ALT = snp
#                         af = format(float(pileup.others[snp][0]) / pileup.count, ".3f").rstrip('0').rstrip('.')
#                         sbq = format(QUAL, ".0f")
#                         smq = format(np.sqrt(float(pileup.others[snp][2]) / pileup.others[snp][0]), ".0f")
#
#                     # ambiguous call
#                     else:
#                         QUAL = 0
#                         snp_count = 0
#                         for _snp in pileup.others:
#                             QUAL += pileup.others[_snp][1]
#                             snp_count += pileup.others[_snp][0]
#                         # qual is RMS of all SNPs... is this right?
#                         # perhaps qual of reference is better, but not sure
#                         QUAL = np.sqrt(float(QUAL) / snp_count)
#                         FILTER = "amb"
#
#                         sorted_alt = pileup.sort_alts()
#                         ALT = ','.join(sorted_alt)
#
#                         for alt in sorted_alt:
#                             temp = pileup.others[alt]
#                             if af:
#                                 af += ','
#                                 sbq += ','
#                                 smq += ','
#                             af += format(float(temp[0]) / pileup.count, ".3f").rstrip('0').rstrip('.')
#                             sbq += format(np.sqrt(float(temp[1]) / temp[0]), ".0f")
#                             smq += format(np.sqrt(float(temp[2]) / temp[0]), ".0f")
#
#                 # else should not have any cases...
#                 else:
#                     print >> logfile, "Uh oh...", str(pileup)
#
#                 if pileup.count:
#                     BQ = np.sqrt(float(pileup.qual_ss) / pileup.count)
#                     MQ = np.sqrt(float(pileup.mq_ss) / pileup.count)
#                 else:
#                     BQ = 0
#                     MQ = 0
#
#                 w.write(vcf_row(CHROM=pileup.chrom,
#                                 POS=pileup.pos,
#                                 ID='.',
#                                 REF=pileup.refbase,
#                                 ALT=ALT,
#                                 QUAL=QUAL,
#                                 FILTER=FILTER,
#                                 DP=pileup.count,
#                                 RF=pileup.ref_fraction(),
#                                 BQ=BQ,
#                                 MQ=MQ,
#                                 AF=af,
#                                 SBQ=sbq,
#                                 SMQ=smq,
#                                 ))
