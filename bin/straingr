#!/usr/bin/env python
"""StrainGR"""
import argparse
import math
import pysam
import numpy as np
import kmertools
import gzip
import cPickle
from numpy import sqrt
from datetime import date

# globals
min_qual = None
min_mq = None
min_confirm = None
min_gap = None
consensus = None
verbose = False

bases = "ACGT"

vcf_header = \
"""##fileformat=VCFv4.0
##fileDate={date}
##source=StrainGR
##reference={ref}
##INFO=<ID=DP,Number=1,Type=Integer,Description="Total Depth">
##INFO=<ID=RF,Number=1,Type=Float,Description="Reference Fraction">
##INFO=<ID=BQ,Number=1,Type=Integer,Description="RMS base quality">
##INFO=<ID=MQ,Number=1,Type=Integer,Description="RMS mapping quality">
##INFO=<ID=AF,Number=.,Type=Float,Description="Allele Frequency">
##INFO=<ID=SBQ,Number=.,Type=Integer,Description="SNP base quality">
##INFO=<ID=SMQ,Number=.,Type=Integer,Description="SNP mapping quality">
##FILTER=<ID=cv,Description="Coverage too low">
##FILTER=<ID=hc,Description="Coverage abnormally high">
##FILTER=<ID=amb,Description="Ambiguous SNP call">
##FILTER=<ID=um,Description="Unmappable position">
##FILTER=<ID=del,Description="Deletion at position">
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO
"""

vcf_row_string = "{CHROM}\t{POS:d}\t{ID}\t{REF}\t{ALT}\t{QUAL:.0f}\t{FILTER}\tDP={DP:d};RF={RF:g};BQ={BQ:.0f};MQ={MQ:.0f}"
def vcf_row(CHROM, POS, ID, REF, ALT, QUAL, FILTER, DP, RF, BQ, MQ, AF=None, SBQ=None, SMQ=None):
    string = vcf_row_string.format(CHROM=CHROM, POS=POS, ID=ID, REF=REF, ALT=ALT, QUAL=QUAL, FILTER=FILTER, DP=DP, RF=RF, BQ=BQ, MQ=MQ)
    if AF:
        string += ";AF={}".format(AF)
    if SBQ:
        string += ";SBQ={}".format(SBQ)
    if SMQ:
        string += ";SMQ={}".format(SMQ)
    
    return string+"\n"
    

class Pileup:
    """
    Class to process pileup information; that is,
    all the alignment information corresponding
    to a given reference coordinate.
    """

    def __init__(self, chrom, scaffold, pos, pileup_reads = []):
        """
        :param scaffold: reference sequence
        :param pos: coordinate in reference (0-based)
        :param pileup_reads: pileup objects from pysam
        """
        self.chrom = chrom
        self.scaffold = scaffold
        self.pos = pos
        self.reads = {}
        self.count = 0
        self.unmapped = 0
        self.bad = 0
        self.mq_total = 0
        self.mq_ss = 0
        self.qual_total = 0
        self.qual_ss = 0
        self.ref_count = 0
        self.ref_qual = 0
        self.ref_qual_ss = 0
        self.ref_mq = 0
        self.ref_mq_ss = 0
        self.hc = False
        # reads with other than reference base; list of tuples (base, qual, mq)
        self.others = {}

        self.refbase = scaffold[pos]
        if not pileup_reads:
            print "No reads for pileup"
            return
        for read in pileup_reads:
            self.add_read(read)

    def add_read(self, read):
        """Add a pysam.PileupRead object to this pileup"""
        alignment = read.alignment

        # if this is a paired read, make sure the pairs are properly aligned
        if (not alignment.is_paired) or (not alignment.is_proper_pair):
            self.bad += 1
            return

        # restrict ourselves to full-length alignments (not clipped)
        if alignment.query_alignment_length != alignment.query_length:
            # alignment is clipped
            self.bad += 1
            return

        # check that inferred insert size is at least read length
        tlen = alignment.template_length
        if abs(tlen) < alignment.query_length:
            self.bad += 1
            return

        # get base quality (note this is next base if deletion)
        pos = read.query_position_or_next
        qual = alignment.query_qualities[pos]
        if qual < min_qual:
            self.bad += 1
            return

        # base call must be real base (e.g., not N)
        base = alignment.query_sequence[pos]
        index = bases.find(base)
        if index < 0:
            self.bad += 1
            return

        # check for decent mapping quality
        mq = alignment.mapping_quality
        if mq < min_mq:
            self.unmapped += 1
            return

        # We're good! Update the pileup stats...
        self.count += 1
        self.mq_ss += mq**2
        self.mq_total += mq
        self.qual_ss += qual**2
        self.qual_total += qual
        # keep track of the reads in this pileup and the position in that read
        self.reads[alignment.query_name] = (pos, base)

        if read.is_del:
            # using N as marker for deletion...
            # workaround until we can write actual deletions into vcf format
            self.add_other("N", qual, mq)
        elif base == self.refbase:
            self.ref_count += 1
            self.ref_qual_ss += qual**2
            self.ref_qual += qual
            self.ref_mq_ss += mq**2
            self.ref_mq += mq
            
        else:
            self.add_other(base, qual, mq)
            if verbose:
                print base, qual, mq

    def add_other(self, base, bq, mq):
        """
        Keep information about bases in pileup which differ from reference.
        :param base: alternate base or 'del' for deletion
        :param bq: base quality
        :param mq: mapping quality
        :return:
        """
        if not self.others:
            self.others = {}
        if base in self.others:
            (count, qss, mqss, qual, mapqual) = self.others[base]
        else:
            count = 0
            qual = 0
            mapqual = 0
            qss = 0
            mqss = 0
        count += 1
        qual += bq
        mapqual += mq
        qss += bq**2
        mqss += mq**2
        self.others[base] = (count, qss, mqss, qual, mapqual)

    def covered(self):
        """Does this pileup have enough data to consider this locus covered?"""
        # this seems wrong
        #return self.ref_qual >= min_confirm and self.count > self.bad
        
        # this seems better...
        #return self.qual_total >= min_confirm and self.count > (self.bad + self.unmapped)

        # why do we care if there are also bad reads as long as there are good ones???
        return self.qual_total >= min_confirm

    def unmappable(self):
        """Good quality sequence, but can't be mapped"""
        return self.unmapped > self.bad

    def ref_fraction(self):
        """Fraction of evidence which supports reference base"""
        if self.qual_total:
            return float(self.ref_qual) / self.qual_total
        else:
            return 0

    def confirmed(self):
        """Does this pileup confirm the reference?"""
        return self.ref_qual >= min_confirm and \
               (self.ref_qual == self.qual_total or self.ref_fraction() > consensus)
    
    def _get_best_snp(self):
        """Returns the SNP with the highest sum of RMS base quality and mapping quality, if two are qual, return higher count. All else equal, alphabetical."""
        best_snp = None
        best_score = 0
        best_count = 0
        if len(self.others) == 1:
            return self.others.keys()[0]
        for snp in self.others:
            # score is just sum of RMS(BQ) and RMS(MQ)
            score = sqrt(float(self.others[snp][1])/self.others[snp][0]) + sqrt(float(self.others[snp][2])/self.others[snp][0])
            count = self.others[snp][0]
            if score > best_score:
                best_snp = snp
                best_score = score
                best_count = count
            elif score == best_score:
                if count > best_count:
                    best_snp = snp
                    best_score = score
                    best_count = count
                elif count == best_count:
                    if verbose: print "Warning: multiple SNPs have same score and count!"
                    return False
        
        return best_snp
        
        #return max(self.others.keys(), key = lambda snp: (sqrt(float(self.others[snp][1])/self.others[snp][0])+sqrt(float(self.others[snp][2])/self.others[snp][0]), self.others[snp][0], snp))
    
    def sort_alts(self):
        return sorted(self.others.keys(), key = lambda snp: (-sqrt(float(self.others[snp][1])/self.others[snp][0]) + sqrt(float(self.others[snp][2])/self.others[snp][0]), -self.others[snp][0], snp))
    
    def base_call(self):
        """Call another base...just print out stats for now"""
        rf = self.ref_fraction()
        if rf < consensus:
            if verbose: print 'SNP?', self.pos, self.scaffold[self.pos], self.count, self.bad, rf, self.others
            
            if len(self.others) == 0:
                if verbose: print "No evidence of SNPs"
            else:
                # get SNP with highest proportion if >1 SNP
                base = self._get_best_snp()
                #if base and self.others[base][0] >= (consensus * self.count) and self.others[base][3] >= min_confirm:
                if base and (float(self.others[base][3]) / self.qual_total) >= consensus and self.others[base][3] >= min_confirm:
                    # 90% of base quality matches SNP
                    if verbose: print "SNP confirmed %s" % base
                    return base
                else:
                    # no consensus
                    if verbose: print "No confirmed SNP"
        
        return None
    
    def high_coverage(self, high):
        """Flag pileup for too much coverage"""
        self.hc = self.count > high
    
    def __str__(self):
        return "<Pileup n=%d rc=%d bad=%d rq=%d/%d mq=%d/%d o=%s>" % (self.count, self.ref_count, self.bad,
                                                                      self.ref_qual, self.qual_total,
                                                                      self.ref_mq, self.mq_total, str(self.others))




def pct(numerator, denominator):
    """Makes into a percent"""
    if numerator > 0 and denominator > 0:
        return (100.0 * numerator) / denominator
    return 0.0

def process_scaffold(bam, scaffold, refseq):
    """Scan the pileups for each locus in the scaffold"""
    length = len(refseq)
    print "Processing", scaffold, length
    confirmed = 0
    covered = 0
    snps = 0
    unmapped = 0
    goodcoverage = 0
    #badcoverage = 0
    #unmappable = 0

    #pileups = [Pileup(refseq, column.reference_pos, column.pileups) for column in bam.pileup(scaffold)]
    pileups = []

    last_covered = -1
    gaps = []
    
    for column in bam.pileup(scaffold):
        refpos = column.reference_pos
        pileup = Pileup(column.reference_name, refseq, refpos, column.pileups)
        if verbose:
            refbase = refseq[refpos]
            print "Ref:", column.reference_name, refpos, refbase, column.nsegments
        goodcoverage += pileup.count
        #badcoverage += pileup.bad
        #unmappable += pileup.unmapped
        if pileup.covered():
            covered += 1
            if pileup.confirmed():
                confirmed += 1
            elif pileup.base_call():
                snps += 1
            if refpos - last_covered > min_gap:
                gap = (last_covered + 1, refpos - last_covered)
                print "Coverage gap:", gap[0], gap[1]
                gaps.append(gap)
            last_covered = refpos
        elif pileup.unmappable():
            unmapped += 1
            # not a real gap, just can't map to this region
            if refpos - last_covered > min_gap:
                gap = (last_covered + 1, refpos - last_covered)
                print "Coverage gap:", gap[0], gap[1]
                gaps.append(gap)
            last_covered = refpos
        
        if verbose:
            print pileup, pileup.confirmed()
        pileups.append(pileup)

    #total = length
    coverage = float(goodcoverage) / float(length)
    #total_coverage = float(goodcoverage + badcoverage + unmappable) / length
    #pct_good = total_coverage and 100.0 * coverage / total_coverage
    mixed = covered - (confirmed + snps)

    print "good coverage: %.1fx" % (coverage,)
    print "covered: %d %.1f%%" % (covered, pct(covered, length))
    print "confirmed: %d %.2f%%" % (confirmed, pct(confirmed, covered))
    print "snps: %d %.3f%%" % (snps, pct(snps, covered))
    if snps > 0:
        print "snp rate: %.0f" % (float(covered) / float(snps))
    print "mixed: %d %.3f%%" % (mixed, pct(mixed, covered))
    if mixed > 0:
        mixed_rate = float(covered) / float(mixed)
        if mixed_rate > 0:
            mixed_quality = math.log10(mixed_rate) * 10.0
        else:
            mixed_quality = 0
        print "mixed rate: %.0f Q%.0f" % (mixed_rate, mixed_quality)
    print "gaps:", len(gaps), "totaling", sum([g[1] for g in gaps])
    print "unmapped: %d %.1f%%" % (unmapped, pct(unmapped, length))
    
    if len(pileups):
        avg_count = goodcoverage / len(pileups)
        if avg_count > 3:
            # threshold is 99.99%ile of poissons distribution at average coverage
            threshold = int(np.percentile(np.random.poisson(avg_count, len(pileups)), 99.99))
        else:
            # at lower coverages, just set it to 10
            threshold = 10
        for pileup in pileups:
            pileup.high_coverage(threshold)
    
    return pileups


def write_vcf(pileups, output=None, date=date.today(), reference=None):
    """Write SNPs to a VCF file"""
    with open(output, 'wb') as w:
        w.write(vcf_header.format(date=date, ref=reference))
        for pileup in pileups:
            af = ''
            sbq = ''
            smq = ''
            ALT = '.'
            
            # start with qual as ref
            if pileup.ref_count:
                QUAL = sqrt(float(pileup.ref_qual_ss)/pileup.ref_count)
            else:
                QUAL = 0
            
            # higher pileup than expected by random chance
            if pileup.hc:
                FILTER = "hc"
            
            # not enough reads to say anything
            elif not pileup.covered():
                # due to not being mappable
                if pileup.unmappable():
                    FILTER = 'um'
                # just not covered enough
                else:
                    FILTER = "cv"
            
            # reference has been confirmed
            elif pileup.confirmed():
                FILTER="PASS"
            
            # reference not confirmed and there are other alleles
            elif pileup.others:
                snp = pileup.base_call()
                
                # confirmed a snp
                if snp:
                    QUAL = sqrt(float(pileup.others[snp][1])/pileup.others[snp][0])
                    FILTER="PASS"
                    ALT = snp
                    af = format(float(pileup.others[snp][0])/pileup.count, ".3f").rstrip('0').rstrip('.')
                    sbq = format(QUAL, ".0f")
                    smq = format(sqrt(float(pileup.others[snp][2])/pileup.others[snp][0]), ".0f")
                
                # ambiguous call
                else:
                    QUAL = 0
                    snp_count = 0
                    for _snp in pileup.others:
                        QUAL += pileup.others[_snp][1]
                        snp_count += pileup.others[_snp][0]
                    # qual is RMS of all SNPs... is this right?
                    # perhaps qual of reference is better, but not sure
                    QUAL = sqrt(float(QUAL)/snp_count)
                    FILTER="amb"
                
                    sorted_alt = pileup.sort_alts()
                    ALT = ','.join(sorted_alt)
                    
                    for alt in sorted_alt:
                        temp = pileup.others[alt]
                        if af:
                            af += ','
                            sbq += ','
                            smq += ','
                        af += format(float(temp[0])/pileup.count, ".3f").rstrip('0').rstrip('.')
                        sbq += format(sqrt(float(temp[1])/temp[0]), ".0f")
                        smq += format(sqrt(float(temp[2])/temp[0]), ".0f")
            
            # else should not have any cases...
            else:
                print "Uh oh...", str(pileup)
            
            if pileup.count:
                BQ = sqrt(float(pileup.qual_ss)/pileup.count)
                MQ = sqrt(float(pileup.mq_ss)/pileup.count)
            else:
                BQ = 0
                MQ = 0
            
            
            w.write(vcf_row(CHROM=pileup.chrom,
                                   POS=pileup.pos,
                                   ID='.',
                                   REF=pileup.refbase,
                                   ALT=ALT,
                                   QUAL=QUAL,
                                   FILTER=FILTER,
                                   DP=pileup.count,
                                   RF=pileup.ref_fraction(),
                                   BQ=BQ,
                                   MQ=MQ,
                                   AF=af,
                                   SBQ=sbq,
                                   SMQ=smq,
                                  ))



def process_bamfile(reference, bamfile):
    """Process a bamfile
    """
    print "Scanning BAM file: %s" % bamfile
    bam = pysam.AlignmentFile(bamfile, "rb")
    all_pileups = []
    for scaffold in bam.references:
        try:
            pileups = process_scaffold(bam, scaffold, reference[scaffold])
            all_pileups.extend(pileups)
        except KeyboardInterrupt:
            raise e
        except Exception as e:
            print "Error in straingr: %s" % e
            continue
    return all_pileups

def save_pileups(pileups, out):
    """Save all pileups to a pickled file"""

    with gzip.open(out, 'wb') as w:
        cPickle.dump(pileups, w)

##################################
### Main
##################################

parser = argparse.ArgumentParser()
parser.add_argument("--verbose", help="increase output verbosity", action="store_true")

parser.add_argument("--minqual", type=int, default=5, help='minimum base quality score to consider')
parser.add_argument("--minmq", type=int, default=5, help='minimum read mapping quality score to consider')
parser.add_argument("--minconfirm", type=int, default=50, help='minimum pileup quality sum to confirm reference or SNP')
parser.add_argument("--mingap", type=int, default=2000, help='minimum contiguous uncovered region to flag')
parser.add_argument("--consensus", type=float, default=0.9, help='minimum fraction of reads to confirm reference or SNP')
parser.add_argument('reference', help='reference FASTA file')
parser.add_argument('bam', nargs='+', help='bam file of reads aligned to reference (sorted & indexed)')
args = parser.parse_args()

# set global options
verbose = args.verbose
min_qual = args.minqual
min_mq = args.minmq
min_confirm = args.minconfirm
min_gap = args.mingap
consensus = args.consensus

print "Loading reference genome"
# add upper to fix lower case reference genomes
reference = {scaffold.name: scaffold.seq.upper() for scaffold in kmertools.openSeqFile(args.reference)}
print len(reference), 'scaffolds,', sum([len(x) for x in reference.values()]), 'bases'

for file in args.bam:
    all_pileups = process_bamfile(reference, file)
    if not all_pileups:
        print "Error: no pileups for %s" % file
        continue
    #if args.out:
    vcf_out = '.'.join(file.split('.')[:-1])+'.vcf'
    print "Writing to vcf file: %s" % vcf_out
    write_vcf(all_pileups, vcf_out, date=date.today(), reference=args.reference)
    save_pileups(all_pileups, '.'.join(file.split('.')[:-1])+'.pkl')