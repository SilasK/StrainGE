#!/usr/bin/env python
"""StrainGR"""

import argparse
import math
import sys
from datetime import date
import numpy as np
import pysam
import kmertools



parser = argparse.ArgumentParser(description="""
Strain Genome Recovery (StrainGR) Tool
""")
parser.add_argument("--output", "-o", action="store_true",
                    help="write stats to tab-delimited file")
parser.add_argument("--verbose", "-v",
                    help="increase output verbosity", action="store_true")
parser.add_argument("--minqual", "-q", type=int, default=5,
                    help='minimum base Quality score to consider')
parser.add_argument("--minmq", "-m", type=int, default=5,
                    help='minimum read Mapping quality score to consider')
parser.add_argument("--minconfirm", "-p", type=int, default=50,
                    help='minimum Pileup quality sum to confirm reference or SNP')
parser.add_argument("--mingap", "-g", type=int, default=2000,
                    help='minimum contiguous uncovered (Gap) region to flag')
parser.add_argument("--log", "-l",
                    help="log file")
parser.add_argument('reference',
                    help="reference FASTA file")
parser.add_argument('bam', nargs='+',
                    help="bam file of reads aligned to reference (sorted & indexed)")
args = parser.parse_args()

logfile = open(args.log, 'w') if args.log else sys.stdout


bases = set(list("ACGT"))

tab_line = "{ref}\t{bam}\t{chrom}\t{length:d}\t{goodcov:.2f}\t{covered:d}\t{pcovered:.1f}\t{confirmed:d}\t{pconfirmed:.2f}\t{snps:d}\t{psnps:.2f}\t{snprate}\t{mixed:d}\t{pmixed:.2f}\t{mixedrate}\t{mixedquality:.0f}\t{gaps:d}\t{gaptotal:d}\t{unmapped:d}\t{highcov:d}\t{highthresh:d}\n"


class Pileup:
    """
    Class to process pileup information; that is,
    all the alignment information corresponding
    to a given reference coordinate.
    """

    # bases and their indicies (plus I for insertion, D for deletion)
    BASES = "ACGTID"
    A = 0
    C = 1
    G = 2
    T = 3
    I = 4
    D = 5
    ALLELES = len(BASES)

    def __init__(self, refbase):
        """
        :param scaffold: reference sequence
        :param pos: coordinate in reference (0-based)
        :param pileup_reads: pileup objects from pysam
        """

        # first dimension is count, qualsum
        self.alleles = np.zeros((2, Pileup.ALLELES), dtype=np.int32)
        # index into allele array for reference base
        self.refindex = Pileup.BASES.find(refbase)
        self.bad = 0
        self.poormq = 0

    def add_reads(self, pileup_reads):
        """Add a bunch of pysam.PileupRead objects to this pileup"""
        for read in pileup_reads:
            self.add_read(read)

    def add_read(self, read):
        """Add a pysam.PileupRead object to this pileup"""
        alignment = read.alignment

        # if this is a paired read, make sure the pairs are properly aligned
        if (not alignment.is_paired) or (not alignment.is_proper_pair):
            self.bad += 1
            return

        # restrict ourselves to full-length alignments (not clipped)
        if alignment.query_alignment_length != alignment.query_length:
            # alignment is clipped
            self.bad += 1
            return

        # check that inferred insert size is at least read length
        tlen = alignment.template_length
        if abs(tlen) < alignment.query_length:
            self.bad += 1
            return

        # get base quality (note this is next base if deletion)
        pos = read.query_position_or_next
        qual = alignment.query_qualities[pos]
        if qual < args.minqual:
            self.bad += 1
            return

        # check for decent mapping quality
        mq = alignment.mapping_quality
        if mq < args.minmq:
            self.poormq += 1
            return

        if read.indel:
            if read.is_del:
                baseIndex = Pileup.D
                # if the base isn't there, base qual doesn't make sense
                qual = mq
            else:
                baseIndex = Pileup.I
        else:
            # base call must be real base (e.g., not N)
            base = alignment.query_sequence[pos]
            baseIndex = Pileup.BASES.find(base)
            if baseIndex < 0:
                self.bad += 1
                return

        # We're good! Update the pileup stats...
        q = min(qual, mq)
        self.alleles[0, baseIndex] += 1
        self.alleles[1, baseIndex] += q

    def depth(self):
        """Sum of all quality evidence"""
        return self.alleles[0].sum()

    def qual_total(self):
        """Sum of all quality evidence"""
        return self.alleles[1].sum()

    def total_depth(self):
        return self.depth() + self.bad

    def covered(self):
        """Does this pileup have enough data to consider this locus covered?"""
        return self.qual_total() >= args.minconfirm

    def unmappable(self):
        """Good quality sequence, but can't be mapped"""
        return self.poormq > (self.total_depth())

    def ref_qual(self):
        return self.alleles[1, self.refindex]

    def ref_fraction(self):
        """Fraction of evidence which supports reference base"""
        return float(self.ref_qual()) / float(self.qual_total())

    def confirmed(self):
        """Does this pileup confirm the reference?"""
        rq = self.ref_qual()
        return rq >= args.minconfirm and \
               (rq == self.qual_total() or self.ref_fraction() > args.consensus)

    def _get_best_snp(self):
        """Returns the SNP with the highest sum of RMS base quality and mapping quality, if two are qual, return higher count. All else equal, alphabetical."""
        best_snp = None
        best_score = 0
        best_count = 0
        if len(self.others) == 1:
            return self.others.keys()[0]
        for snp in self.others:
            # score is just sum of RMS(BQ) and RMS(MQ)
            score = np.sqrt(float(self.others[snp][1]) / self.others[snp][0]) + np.sqrt(
                float(self.others[snp][2]) / self.others[snp][0])
            count = self.others[snp][0]
            if score > best_score:
                best_snp = snp
                best_score = score
                best_count = count
            elif score == best_score:
                if count > best_count:
                    best_snp = snp
                    best_score = score
                    best_count = count
                elif count == best_count:
                    if args.verbose: print >> logfile, "Warning: multiple SNPs have same score and count!"
                    return False

        return best_snp

        # return max(self.others.keys(), key = lambda snp: (np.sqrt(float(self.others[snp][1])/self.others[snp][0])+np.sqrt(float(self.others[snp][2])/self.others[snp][0]), self.others[snp][0], snp))

    def sort_alts(self):
        return sorted(self.others.keys(), key=lambda snp: (
        -np.sqrt(float(self.others[snp][1]) / self.others[snp][0]) + np.sqrt(
            float(self.others[snp][2]) / self.others[snp][0]), -self.others[snp][0], snp))

    def base_call(self):
        """Call another base...just print out stats for now"""
        rf = self.ref_fraction()
        if rf < consensus:
            if args.verbose: print >> logfile, 'SNP?', self.pos, self.refbase, self.count, self.bad, rf, self.others

            if len(self.others) == 0:
                if args.verbose: print >> logfile, "No evidence of SNPs"
            else:
                # get SNP with highest proportion if >1 SNP
                snp_base = self._get_best_snp()
                # if base and self.others[base][0] >= (consensus * self.count) and self.others[base][3] >= min_confirm:
                if snp_base and (float(self.others[snp_base][3]) / self.qual_total) >= consensus and \
                                self.others[snp_base][3] >= min_confirm:
                    # 90% of base quality matches SNP
                    if args.verbose: print >> logfile, "SNP confirmed %s" % snp_base
                    return snp_base
                else:
                    # no consensus
                    if args.verbose: print >> logfile, "No confirmed SNP"

        return None

    def high_coverage(self, high):
        """Flag pileup for too much coverage"""
        self.hc = self.count > high
        if self.hc:
            return 1
        else:
            return 0

    def __str__(self):
        return "<Pileup n=%d b=%s bad=%d rq=%d>" % (self.depth(), str(self.alleles), self.bad,
                                                                      self.ref_qual())


class Scaffold:
    def __init__(self, name, sequence):
        self.name = name
        self.sequence = sequence
        self.length = len(sequence)
        self.covered = 0
        self.confirmed = 0
        self.snps = 0
        self.unmapped = 0
        self.goodcoverage = 0
        self.highcoverage = 0
        self.gaps = []
        #self.pileups = np.full((self.length,), None, dtype=np.dtype(object))
        self.pileups = np.array([Pileup(base) for base in sequence], dtype=np.dtype(object))

        # Will hold coverage array after pileups are generated
        self.coverage = None


    def makePileups(self, bam):
        print >>logfile, "Processing", self.name, "length", self.length,
        logfile.flush()

        for column in bam.pileup(self.name):
            refpos = column.reference_pos
            self.pileups[refpos].add_reads(column.pileups)
            #pileup = Pileup(self.sequence[refpos])
            #pileup.add_reads(column.pileups)
            #self.pileups[refpos] = pileup
        self.coverage = np.array([p.depth() for p in self.pileups], dtype=np.int32)
        print >>logfile, "raw coverage %.2f" % (self.coverage.sum() / float(self.length))
        logfile.flush()


    def process(self, bam):
        """Scan the pileups for each locus in the scaffold"""

        print >>logfile, "Processing", self.name, self
        last_covered = -1
        goodcoverage = 0

        for column in bam.pileup(self.name):
            refpos = column.reference_pos
            pileup = Pileup(self.sequence[refpos])
            pileup.add_reads(column.pileups)
            self.pileups[refpos] = pileup

            if args.verbose:
                refbase = self.sequence[refpos]
                print >> logfile, "Ref:", column.reference_name, refpos, refbase, column.nsegments
            goodcoverage += pileup.depth()
            if pileup.covered():
                covered += 1
                if pileup.confirmed():
                    confirmed += 1
                else:
                    # keep read info for covered, non-ref alleles
                    # self.insert_into_db(pileup)
                    if pileup.base_call():
                        snps += 1
                if refpos - last_covered > args.min_gap:
                    gap = (last_covered + 1, refpos - last_covered)
                    print >> logfile, "Coverage gap:", gap[0], gap[1]
                    gaps.append(gap)
                last_covered = refpos
            else:
                if pileup.unmappable():
                    unmapped += 1
                    # not a real gap, just can't map to this region
                    if refpos - last_covered > args.min_gap:
                        gap = (last_covered + 1, refpos - last_covered)
                        print >> logfile, "Coverage gap:", gap[0], gap[1]
                        gaps.append(gap)
                    last_covered = refpos
                    # if keep:
                    # keep all pileups anyway
                    # self.insert_into_db(pileup)

            # del pileup.reads

            if args.verbose:
                print >> logfile, pileup, pileup.confirmed()

        coverage = float(goodcoverage) / float(length)
        mixed = covered - (confirmed + snps)

        print >> logfile, "good coverage: %.1fx" % (coverage,)
        print >> logfile, "covered: %d %.1f%%" % (covered, pct(covered, length))
        print >> logfile, "confirmed: %d %.2f%%" % (confirmed, pct(confirmed, covered))
        print >> logfile, "snps: %d %.3f%%" % (snps, pct(snps, covered))
        if snps > 0:
            snp_rate = "%.0f" % (float(covered) / float(snps))
            print >> logfile, "snp rate:", snp_rate
        else:
            snp_rate = ""
        print >> logfile, "mixed: %d %.3f%%" % (mixed, pct(mixed, covered))
        if mixed > 0:
            mixed_rate = float(covered) / float(mixed)
            if mixed_rate > 0:
                mixed_quality = math.log10(mixed_rate) * 10.0
            else:
                mixed_quality = 0
            mixed_rate = "%.0f" % (mixed_rate)
            print >> logfile, "mixed rate: %s Q%.0f" % (mixed_rate, mixed_quality)
        else:
            mixed_rate = ""
            mixed_quality = 0
        gap_total = sum([g[1] for g in gaps])
        print >> logfile, "gaps:", len(gaps), "totaling", gap_total
        print >> logfile, "unmapped: %d %.1f%%" % (unmapped, pct(unmapped, length))


class Reference:
    def __init__(self, fasta):
        self.scaffolds = [Scaffold(scaffold.name, scaffold.seq.upper()) for scaffold in kmertools.openSeqFile(fasta)]
        self.length = sum([s.length for s in self.scaffolds])
        print >>logfile, "Reference has", len(self.scaffolds), "scaffolds containing", self.length, "bases"
        self.coverage = None

    def process(self, bam):
        with pysam.AlignmentFile(bamfile, "rb") as bam:
            for s in self.scaffolds:
                s.makePileups(bam)

        coverage = np.concatenate([s.coverage for s in self.scaffolds])
        meanCoverage = coverage.sum() / float(self.length)
        highCutoff = self.poissonCutoff(meanCoverage)
        print >>logfile, "Total coverage", self.length, round(meanCoverage, 2), highCutoff,

        nonzero = coverage[coverage > 0]
        nonzeroCoverage = float(nonzero.sum()) / float(nonzero.size)
        highCutoff = self.poissonCutoff(nonzeroCoverage)
        print >>logfile, "nonzero", nonzero.size, round(nonzeroCoverage, 2), highCutoff,

        nice = nonzero[nonzero < highCutoff]
        niceCoverage = float(nice.sum()) / float(nice.size)
        print >>logfile, "nice", nice.size, round(niceCoverage, 2)

    def poissonCutoff(self, mean, cutoff = 0.9999999):
        """Calculate the Poisson CDF and find where it reaches the cutoff"""
        i = 0
        ifact = 1.0
        expmean = math.exp(-mean)
        cdf = 0.0
        while cdf < cutoff:
            cdf += expmean * math.pow(mean, i) / ifact
            i += 1
            ifact *= i
        return i - 1


def pct(numerator, denominator):
    """Makes into a percent"""
    if numerator > 0 and denominator > 0:
        return (100.0 * numerator) / denominator
    return 0.0


vcf_header = \
"""##fileformat=VCFv4.0
##fileDate={date}
##source=StrainGR
##reference={ref}
##INFO=<ID=DP,Number=1,Type=Integer,Description="Total Depth">
##INFO=<ID=RF,Number=1,Type=Float,Description="Reference Fraction">
##INFO=<ID=BQ,Number=1,Type=Integer,Description="RMS base quality">
##INFO=<ID=MQ,Number=1,Type=Integer,Description="RMS mapping quality">
##INFO=<ID=AF,Number=.,Type=Float,Description="Allele Frequency">
##INFO=<ID=SBQ,Number=.,Type=Integer,Description="SNP base quality">
##INFO=<ID=SMQ,Number=.,Type=Integer,Description="SNP mapping quality">
##FILTER=<ID=cv,Description="Coverage too low">
##FILTER=<ID=hc,Description="Coverage abnormally high">
##FILTER=<ID=amb,Description="Ambiguous SNP call">
##FILTER=<ID=um,Description="Unmappable position">
##FILTER=<ID=del,Description="Deletion at position">
#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO
"""

vcf_row_string = "{CHROM}\t{POS:d}\t{ID}\t{REF}\t{ALT}\t{QUAL:.0f}\t{FILTER}\tDP={DP:d};RF={RF:g};BQ={BQ:.0f};MQ={MQ:.0f}"

def vcf_row(CHROM, POS, ID, REF, ALT, QUAL, FILTER, DP, RF, BQ, MQ, AF=None, SBQ=None, SMQ=None):
    string = vcf_row_string.format(CHROM=CHROM, POS=POS, ID=ID, REF=REF, ALT=ALT, QUAL=QUAL, FILTER=FILTER, DP=DP, RF=RF, BQ=BQ, MQ=MQ)
    if AF:
        string += ";AF={}".format(AF)
    if SBQ:
        string += ";SBQ={}".format(SBQ)
    if SMQ:
        string += ";SMQ={}".format(SMQ)
    
    return string+"\n"


def write_vcf(pileups, output=None, date=date.today(), reference=None):
    """Write SNPs to a VCF file"""
    with open(output, 'wb') as w:
        w.write(vcf_header.format(date=date, ref=reference))
        # for pileup in pileups:
        for scaffold in pileups.pileups:
            for refpos in pileups.pileups[scaffold]:
                pileup = pileups.pileups[scaffold][refpos]
                af = ''
                sbq = ''
                smq = ''
                ALT = '.'
                
                # start with qual as ref
                if pileup.ref_count:
                    QUAL = np.sqrt(float(pileup.ref_qual_ss)/pileup.ref_count)
                else:
                    QUAL = 0
                
                # higher pileup than expected by random chance
                if pileup.hc:
                    FILTER = "hc"
                
                # not enough reads to say anything
                elif not pileup.covered():
                    # due to not being mappable
                    if pileup.unmappable():
                        FILTER = 'um'
                    # just not covered enough
                    else:
                        FILTER = "cv"
                
                # reference has been confirmed
                elif pileup.confirmed():
                    FILTER="PASS"
                
                # reference not confirmed and there are other alleles
                elif pileup.others:
                    snp = pileup.base_call()
                    
                    # confirmed a snp
                    if snp:
                        QUAL = np.sqrt(float(pileup.others[snp][1])/pileup.others[snp][0])
                        FILTER="PASS"
                        ALT = snp
                        af = format(float(pileup.others[snp][0])/pileup.count, ".3f").rstrip('0').rstrip('.')
                        sbq = format(QUAL, ".0f")
                        smq = format(np.sqrt(float(pileup.others[snp][2])/pileup.others[snp][0]), ".0f")
                    
                    # ambiguous call
                    else:
                        QUAL = 0
                        snp_count = 0
                        for _snp in pileup.others:
                            QUAL += pileup.others[_snp][1]
                            snp_count += pileup.others[_snp][0]
                        # qual is RMS of all SNPs... is this right?
                        # perhaps qual of reference is better, but not sure
                        QUAL = np.sqrt(float(QUAL)/snp_count)
                        FILTER="amb"
                    
                        sorted_alt = pileup.sort_alts()
                        ALT = ','.join(sorted_alt)
                        
                        for alt in sorted_alt:
                            temp = pileup.others[alt]
                            if af:
                                af += ','
                                sbq += ','
                                smq += ','
                            af += format(float(temp[0])/pileup.count, ".3f").rstrip('0').rstrip('.')
                            sbq += format(np.sqrt(float(temp[1])/temp[0]), ".0f")
                            smq += format(np.sqrt(float(temp[2])/temp[0]), ".0f")
                
                # else should not have any cases...
                else:
                    print >>logfile, "Uh oh...", str(pileup)
                
                if pileup.count:
                    BQ = np.sqrt(float(pileup.qual_ss)/pileup.count)
                    MQ = np.sqrt(float(pileup.mq_ss)/pileup.count)
                else:
                    BQ = 0
                    MQ = 0
                
                
                w.write(vcf_row(CHROM=pileup.chrom,
                                    POS=pileup.pos,
                                    ID='.',
                                    REF=pileup.refbase,
                                    ALT=ALT,
                                    QUAL=QUAL,
                                    FILTER=FILTER,
                                    DP=pileup.count,
                                    RF=pileup.ref_fraction(),
                                    BQ=BQ,
                                    MQ=MQ,
                                    AF=af,
                                    SBQ=sbq,
                                    SMQ=smq,
                                    ))


##################################
### Main
##################################

print >>logfile, "Loading reference genome"
# add upper to fix lower case reference genomes
reference = Reference(args.reference)

fileout = None
for bamfile in args.bam:
    if args.output:
        fileout = '.'.join(bamfile.split('.')[:-1]) + '.stats.txt'
    reference.process(bamfile)

    #vcf_out = '.'.join(file.split('.')[:-1])+'.vcf'
    #print >>log, "Writing to vcf file: %s" % vcf_out
    #write_vcf(pileups, vcf_out, date=date.today(), reference=args.reference)
    # pkl_out = '.'.join(file.split('.')[:-1])+'.pkl'
    # print >>log, "Writing to pickle file: %s" % pkl_out
    # grtools.save_pileups(pileups, pkl_out)


########## ARCHIVE




class OldPileup:
    """
    Class to process pileup information; that is,
    all the alignment information corresponding
    to a given reference coordinate.
    """

    def __init__(self, chrom, scaffold, pos, pileup_reads=None, fileout=None):
        """
        :param scaffold: reference sequence
        :param pos: coordinate in reference (0-based)
        :param pileup_reads: pileup objects from pysam
        """
        self.chrom = chrom
        self.pos = pos
        # self.reads = {}
        self.count = 0
        self.unmapped = 0
        self.bad = 0
        self.mq_total = 0
        self.mq_ss = 0
        self.qual_total = 0
        self.qual_ss = 0
        self.ref_count = 0
        self.ref_qual = 0
        self.ref_qual_ss = 0
        self.ref_mq = 0
        self.ref_mq_ss = 0
        self.hc = False
        self.fileout = fileout
        # reads with other than reference base; list of tuples (base, qual, mq)
        self.others = {}

        self.refbase = scaffold[pos]
        if not pileup_reads:
            print >> logfile, "No reads for pileup"
            return
        for read in pileup_reads:
            self.add_read(read)

    def add_read(self, read):
        """Add a pysam.PileupRead object to this pileup"""
        alignment = read.alignment

        # if this is a paired read, make sure the pairs are properly aligned
        if (not alignment.is_paired) or (not alignment.is_proper_pair):
            self.bad += 1
            return

        # restrict ourselves to full-length alignments (not clipped)
        if alignment.query_alignment_length != alignment.query_length:
            # alignment is clipped
            self.bad += 1
            return

        # check that inferred insert size is at least read length
        tlen = alignment.template_length
        if abs(tlen) < alignment.query_length:
            self.bad += 1
            return

        # get base quality (note this is next base if deletion)
        pos = read.query_position_or_next
        qual = alignment.query_qualities[pos]
        if qual < min_qual:
            self.bad += 1
            return

        # base call must be real base (e.g., not N)
        base = alignment.query_sequence[pos]
        if base not in bases:
            self.bad += 1
            return

        # check for decent mapping quality
        mq = alignment.mapping_quality
        if mq < min_mq:
            self.unmapped += 1
            return

        # We're good! Update the pileup stats...
        self.count += 1
        self.mq_ss += mq ** 2
        self.mq_total += mq
        self.qual_ss += qual ** 2
        self.qual_total += qual
        # keep track of the reads in this pileup and the position in that read

        # read_name = alignment.query_name
        # if alignment.is_read1:
        #     read_name += ".1"
        # else:
        #     read_name += ".2"

        # self.reads[read_name] = pos
        if read.is_del:
            # using N as marker for deletion...
            # workaround until we can write actual deletions into vcf format
            self.add_other("N", qual, mq)
            # self.reads[read_name] = (pos, "del")

        else:
            # self.reads[read_name] = (pos, base)
            if base == self.refbase:
                self.ref_count += 1
                self.ref_qual_ss += qual ** 2
                self.ref_qual += qual
                self.ref_mq_ss += mq ** 2
                self.ref_mq += mq

            else:
                self.add_other(base, qual, mq)
                if verbose:
                    print >> logfile, base, qual, mq

    def add_other(self, base, bq, mq):
        """
        Keep information about bases in pileup which differ from reference.
        :param base: alternate base or 'del' for deletion
        :param bq: base quality
        :param mq: mapping quality
        :return:
        """
        if not self.others:
            self.others = {}
        if base in self.others:
            (count, qss, mqss, qual, mapqual) = self.others[base]
        else:
            count = 0
            qual = 0
            mapqual = 0
            qss = 0
            mqss = 0
        count += 1
        qual += bq
        mapqual += mq
        qss += bq ** 2
        mqss += mq ** 2
        self.others[base] = (count, qss, mqss, qual, mapqual)

    def covered(self):
        """Does this pileup have enough data to consider this locus covered?"""
        # this seems wrong
        # return self.ref_qual >= min_confirm and self.count > self.bad

        # this seems better...
        # return self.qual_total >= min_confirm and self.count > (self.bad + self.unmapped)

        # why do we care if there are also bad reads as long as there are good ones???
        return self.qual_total >= min_confirm

    def unmappable(self):
        """Good quality sequence, but can't be mapped"""
        return self.unmapped > (self.bad + self.count)

    def ref_fraction(self):
        """Fraction of evidence which supports reference base"""
        if self.qual_total:
            return float(self.ref_qual) / self.qual_total
        else:
            return 0

    def confirmed(self):
        """Does this pileup confirm the reference?"""
        return self.ref_qual >= min_confirm and \
               (self.ref_qual == self.qual_total or self.ref_fraction() > consensus)

    def _get_best_snp(self):
        """Returns the SNP with the highest sum of RMS base quality and mapping quality, if two are qual, return higher count. All else equal, alphabetical."""
        best_snp = None
        best_score = 0
        best_count = 0
        if len(self.others) == 1:
            return self.others.keys()[0]
        for snp in self.others:
            # score is just sum of RMS(BQ) and RMS(MQ)
            score = np.sqrt(float(self.others[snp][1]) / self.others[snp][0]) + np.sqrt(
                float(self.others[snp][2]) / self.others[snp][0])
            count = self.others[snp][0]
            if score > best_score:
                best_snp = snp
                best_score = score
                best_count = count
            elif score == best_score:
                if count > best_count:
                    best_snp = snp
                    best_score = score
                    best_count = count
                elif count == best_count:
                    if verbose: print >> logfile, "Warning: multiple SNPs have same score and count!"
                    return False

        return best_snp

        # return max(self.others.keys(), key = lambda snp: (np.sqrt(float(self.others[snp][1])/self.others[snp][0])+np.sqrt(float(self.others[snp][2])/self.others[snp][0]), self.others[snp][0], snp))

    def sort_alts(self):
        return sorted(self.others.keys(), key=lambda snp: (
        -np.sqrt(float(self.others[snp][1]) / self.others[snp][0]) + np.sqrt(
            float(self.others[snp][2]) / self.others[snp][0]), -self.others[snp][0], snp))

    def base_call(self):
        """Call another base...just print out stats for now"""
        rf = self.ref_fraction()
        if rf < consensus:
            if verbose: print >> logfile, 'SNP?', self.pos, self.refbase, self.count, self.bad, rf, self.others

            if len(self.others) == 0:
                if verbose: print >> logfile, "No evidence of SNPs"
            else:
                # get SNP with highest proportion if >1 SNP
                snp_base = self._get_best_snp()
                # if base and self.others[base][0] >= (consensus * self.count) and self.others[base][3] >= min_confirm:
                if snp_base and (float(self.others[snp_base][3]) / self.qual_total) >= consensus and \
                                self.others[snp_base][3] >= min_confirm:
                    # 90% of base quality matches SNP
                    if verbose: print >> logfile, "SNP confirmed %s" % snp_base
                    return snp_base
                else:
                    # no consensus
                    if verbose: print >> logfile, "No confirmed SNP"

        return None

    def high_coverage(self, high):
        """Flag pileup for too much coverage"""
        self.hc = self.count > high
        if self.hc:
            return 1
        else:
            return 0

    def __str__(self):
        return "<Pileup n=%d rc=%d bad=%d rq=%d/%d mq=%d/%d o=%s>" % (self.count, self.ref_count, self.bad,
                                                                      self.ref_qual, self.qual_total,
                                                                      self.ref_mq, self.mq_total, str(self.others))



class Pileups:
    """Class of Pileups and reads for straingr"""

    def __init__(self, reference, bamfile, keep=False, refname="", fileout=None):

        # connect to database & create table
        # if os.path.isfile(bamfile+".db"):
        #     print >>log, "Deleting old database file"
        #     os.remove(bamfile+".db")
        # self.con = sqlite3.connect(bamfile+".db")
        # self.con.execute("CREATE TABLE reads (read TEXT, readpos INTEGER, scaffold TEXT, pos INTEGER, base TEXT)")
        self.refname = refname
        self.bamfile = bamfile
        self.pileups = {}
        # self.reads = {}
        self.nPileups = 0
        self.length = 0
        self.confirmed = 0
        self.covered = 0
        self.snps = 0
        self.unmapped = 0
        self.goodcoverage = 0
        self.highcoverage = 0
        if fileout:
            self.fileout = open(fileout, 'wb')
            self.fileout.write(
                "reference\tbam\tchrom\tlength\tgoodcov\tcovered\tpcovered\tconfirmed\tpconfirmed\tsnps\tpsnps\tsnprate\tmixed\tpmixed\tmixedrate\tmixedquality\tgaps\tgaptotal\tunmapped\thighcov\thighthresh\n")
        else:
            self.fileout = None

        print >> logfile, "Scanning BAM file: %s" % bamfile
        bam = pysam.AlignmentFile(bamfile, "rb")

        for scaffold in bam.references:
            try:
                self.process_scaffold(bam, scaffold, reference[scaffold], keep=keep)
            except KeyboardInterrupt:
                raise
            except Exception as e:
                print >> logfile, "Error in straingr: %s" % e
                raise

        if self.fileout:
            self.fileout.close()

    def __len__(self):
        return self.nPileups

    def insert_into_db(self, pileup):
        # reads = []
        # for read in pileup.reads:
        #     (pos, base) = pileup.reads[read]
        #     reads.append((read, pos, pileup.chrom, pileup.pos, base))
        # self.con.executemany("INSERT INTO reads(read, readpos, scaffold, pos, base) VALUES(?, ?, ?, ?, ?)", reads)
        for read in pileup.reads:
            if read not in self.reads:
                self.reads[read] = {"pileups": {}, "scaffold": pileup.chrom}
            (pos, base) = pileup.reads[read]
            self.reads[read]["pileups"][pos] = dict(base=base, refpos=pileup.pos)

    def process_scaffold(self, bam, scaffold, refseq, keep=False):
        """Scan the pileups for each locus in the scaffold"""

        self.pileups[scaffold] = {}
        length = len(refseq)
        print >> logfile, "Processing", scaffold, length
        covered = 0
        confirmed = 0
        snps = 0
        unmapped = 0
        goodcoverage = 0
        highcoverage = 0

        last_covered = -1
        gaps = []

        for column in bam.pileup(scaffold):
            refpos = column.reference_pos
            pileup = Pileup(column.reference_name, refseq, refpos, column.pileups)

            if verbose:
                refbase = refseq[refpos]
                print >> logfile, "Ref:", column.reference_name, refpos, refbase, column.nsegments
            goodcoverage += pileup.count
            if pileup.covered():
                covered += 1
                if pileup.confirmed():
                    confirmed += 1
                else:
                    # keep read info for covered, non-ref alleles
                    # self.insert_into_db(pileup)
                    if pileup.base_call():
                        snps += 1
                if refpos - last_covered > min_gap:
                    gap = (last_covered + 1, refpos - last_covered)
                    print >> logfile, "Coverage gap:", gap[0], gap[1]
                    gaps.append(gap)
                last_covered = refpos
            else:
                if pileup.unmappable():
                    unmapped += 1
                    # not a real gap, just can't map to this region
                    if refpos - last_covered > min_gap:
                        gap = (last_covered + 1, refpos - last_covered)
                        print >> logfile, "Coverage gap:", gap[0], gap[1]
                        gaps.append(gap)
                    last_covered = refpos
                    # if keep:
                    # keep all pileups anyway
                    # self.insert_into_db(pileup)

            # del pileup.reads

            if verbose:
                print >> logfile, pileup, pileup.confirmed()
            self.pileups[scaffold][refpos] = pileup

        coverage = float(goodcoverage) / float(length)
        mixed = covered - (confirmed + snps)

        print >> logfile, "good coverage: %.1fx" % (coverage,)
        print >> logfile, "covered: %d %.1f%%" % (covered, pct(covered, length))
        print >> logfile, "confirmed: %d %.2f%%" % (confirmed, pct(confirmed, covered))
        print >> logfile, "snps: %d %.3f%%" % (snps, pct(snps, covered))
        if snps > 0:
            snp_rate = "%.0f" % (float(covered) / float(snps))
            print >> logfile, "snp rate:", snp_rate
        else:
            snp_rate = ""
        print >> logfile, "mixed: %d %.3f%%" % (mixed, pct(mixed, covered))
        if mixed > 0:
            mixed_rate = float(covered) / float(mixed)
            if mixed_rate > 0:
                mixed_quality = math.log10(mixed_rate) * 10.0
            else:
                mixed_quality = 0
            mixed_rate = "%.0f" % (mixed_rate)
            print >> logfile, "mixed rate: %s Q%.0f" % (mixed_rate, mixed_quality)
        else:
            mixed_rate = ""
            mixed_quality = 0
        gap_total = sum([g[1] for g in gaps])
        print >>logfile, "gaps:", len(gaps), "totaling", gap_total
        print >>logfile, "unmapped: %d %.1f%%" % (unmapped, pct(unmapped, length))

        # keep track of total values in the Pileups class variables
        self.length += length
        self.confirmed += confirmed
        self.covered += covered
        self.snps += snps
        self.unmapped += unmapped
        self.goodcoverage += goodcoverage

        if len(self.pileups[scaffold]):
            avg_count = goodcoverage / len(self.pileups[scaffold])
            if avg_count > 3:
                # threshold is 99.9999%ile of poissons distribution at average coverage
                threshold = int(np.percentile(np.random.poisson(avg_count, self.nPileups), 99.9999))
            else:
                # at lower coverages, just set it to 15
                threshold = 15
            for refpos in self.pileups[scaffold]:
                highcoverage += self.pileups[scaffold][refpos].high_coverage(threshold)

            print >>logfile, "Abnormally high coverage: %d %.2f%% (expect 0.01%% false positive)" % (highcoverage, pct(highcoverage, length))

            self.highcoverage += highcoverage
        else:
            highcoverage = 0
            threshold = 0

            # "{bam}\t{chrom}\t{length:d}\t{goodcov:.2f}x\t{covered:d}\t{confirmed:d}\t{snps:d}\t{snprate}\t{mixed:d}\t{mixedrate}\tQ{mixedquality:.0f}\t{gaps:d}\t{gaptotal:d}\t{unmapped:d}\t{highcov:d}\t{highthresh:d}\n"
        if self.fileout:
            self.fileout.write(tab_line.format(ref=self.refname,
                                               bam=self.bamfile,
                                               chrom=scaffold,
                                               length=length,
                                               goodcov=coverage,
                                               covered=covered,
                                               pcovered=pct(covered, length),
                                               confirmed=confirmed,
                                               pconfirmed=pct(confirmed, covered),
                                               snps=snps,
                                               psnps=pct(snps, covered),
                                               snprate=snp_rate,
                                               mixed=mixed,
                                               pmixed=pct(mixed, covered),
                                               mixedrate=mixed_rate,
                                               mixedquality=mixed_quality,
                                               gaps=len(gaps),
                                               gaptotal=gap_total,
                                               unmapped=unmapped,
                                               highcov=highcoverage,
                                               highthresh=threshold))


