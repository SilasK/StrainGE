#!/usr/bin/env python
import sys
import argparse
# import time
import numpy as np
import kmertools
import kmerizer
import math
import h5py


parser = argparse.ArgumentParser()
parser.add_argument("-f", "--fingerprint", help="use minhash fingerprint instead of full kmer set to build graph",
                    action="store_true")
parser.add_argument("-v", "--verbose", action='store_true', help="More output")
parser.add_argument("-c", "--cache", action='store_true', help="Cache strain kmer sets between iterations (uses more memory)")
parser.add_argument("-K", type=int, default=kmertools.DEFAULT_K, help="Kmer size (default: %d)" % (kmertools.DEFAULT_K))
parser.add_argument("-o", "--output", help="output text file (default: standard out)")
parser.add_argument("-i", "--iterations", type=int, default=2, help="how many strains to look for (default: 2)")
parser.add_argument("-m", "--min", type=int, default=0, help="Minimum number of kmers left to prematurely end iterations (default: disabled)")
parser.add_argument("-t", "--top", type=int, default=1, help="How many best matches to print (default: 1)")
parser.add_argument("-r", "--readlength", type=int, default=101, help="Read length (for better coverage estimates, default: 101)")
parser.add_argument("pan", help="hdf5 file containing pan genome kmer set")
parser.add_argument("sample", help="Compare similarity of this vs the other strains instead of all vs all")
args = parser.parse_args()

# coverage normalization factor
covmult = float(args.readlength) / float(args.readlength - args.K + 1)

print >>sys.stderr, "Loading sample", args.sample
sample = kmertools.kmerSetFromFile(args.sample)

exclude = None

if args.output:
    output = open(args.output, 'w')
    output.write("i\tcov\tkcov\tgcov\tacct\teven\tscore\tscore2\n")
else:
    output = sys.stdout

with h5py.File(args.pan, 'r') as h5:
    print >>sys.stderr, "Loading pan genome"
    pan = kmertools.KmerSet()
    pan.load_hdf5(h5)

    # common kmers contains all kmers of sample which are in pangenome
    panSampleKmers = kmerizer.intersect(sample.kmers, pan.kmers)
    print >>sys.stderr, panSampleKmers.size, "pan kmers in sample"
    # how often each common kmer occurs in sample
    panSampleCounts = kmerizer.intersect_counts(sample.kmers, sample.counts, panSampleKmers)
    # how often each common kmer occurs in pangenome
    samplePanCounts = kmerizer.intersect_counts(pan.kmers, pan.counts, panSampleKmers)
    assert panSampleKmers.size == panSampleCounts.size == samplePanCounts.size, "Intersection kmers & counts differ in size"

    # release sample from memory
    sample = None
    strainKmerSets = {}

    print 

    for i in range(args.iterations):
        print >>sys.stderr, "Finding strain", i + 1
        results = []
        bestScore = 0
        bestKset = None

        # loop over strains in pangenome file
        for name in h5.keys():
            # Strain KmerSets are in groups
            if not isinstance(h5[name], h5py.Group):
                continue

            if name in strainKmerSets:
                strain = strainKmerSets[name]
            else:
                strain = kmertools.KmerSet()
                strain.load_hdf5(h5[name])

            # t0 = time.time()

            if args.fingerprint and exclude is None:
                strain.kmers = strain.fingerprint
                strain.counts = np.ones_like(strain.fingerprint, dtype=np.int64)


            if exclude is not None:
                keepers = np.setdiff1d(strain.kmers, exclude, assume_unique=True)
                if float(keepers.size) / float(strain.kmers.size) < 0.05:
                    break
                strain.counts = kmerizer.intersect_counts(strain.kmers, strain.counts, keepers)
                strain.kmers = keepers

            if args.cache:
                strainKmerSets[name] = strain


            # t1 = time.time()

            strainSampleKmers = kmerizer.intersect(panSampleKmers, strain.kmers)
            if strainSampleKmers.size == 0:
                continue
            strainSampleCounts = kmerizer.intersect_counts(panSampleKmers, panSampleCounts, strain.kmers)
            strainSampleCount = strainSampleCounts.sum()
            sampleStrainCounts = kmerizer.intersect_counts(strain.kmers, strain.counts, panSampleKmers)
            sampleStrainCount = sampleStrainCounts.sum()
            assert strainSampleKmers.size == strainSampleCounts.size == sampleStrainCounts.size, "length mismatch"

            # Fraction of strain kmers in sample
            covered = float(strainSampleKmers.size) / float(strain.kmers.size)
            # kmer coverage: mean coverage of every strain kmer that is in the sample
            kcoverage = float(strainSampleCount) / float(strainSampleKmers.size)
            # genome coverage: mean coverage of every strain kmer
            gcoverage = covmult * float(strainSampleCount) / float(strain.counts.sum())

            # converse of covered: what fraction of pangenome sample kmers are in this strain?
            accounted = float(strainSampleKmers.size) / float(panSampleKmers.size)

            # t2 = time.time()

            # Lander-Waterman estimate of percentage covered if uniform
            estCovered = 1.0 - math.exp(-gcoverage)
            # measure of evenness of coverage
            evenness = covered / estCovered

            # Weights of each kmer in strain (inverse of occurrence in pangenome)
            strainPanCounts = kmerizer.intersect_counts(pan.kmers, pan.counts, strain.kmers)
            strainWeights = 1.0 / strainPanCounts
            strainTotalWeight = (strainWeights * strain.counts).sum()

            strainSampleWeights = 1.0 / kmerizer.intersect_counts(strain.kmers, strainPanCounts, strainSampleKmers)
            countweight = (strainSampleCounts * strainSampleWeights).sum()
            wcoverage = covmult * countweight / strainTotalWeight
            # wsample = countweight / (1.0 / samplePanCounts).sum()
            #
            specificity = wcoverage / gcoverage

            score = covered * accounted * evenness
            score2 = covered * accounted * min(specificity, 1/specificity)

            # t3 = time.time()
            # print 'Times:', t1-t0, t2-t1, t3-t2

            result = (i, name, covered, kcoverage, gcoverage, specificity, accounted, evenness, score, score2)
            results.append(result)

            # If this is the winner, keep the kmers around
            if result[-1] > bestScore:
                bestScore = result[-1]
                bestKmers = strainSampleKmers

            if args.verbose:
                print >>sys.stderr, "%32s cov %.3f kcov %.2f gcov %.2f spec %.2f acct %.3f even %.3f score %.3f score2 %.3f" % result[1:]

        # print name, "covered: %.3f kcov: %.2f gcov: %.2f wcov: %.2f score: %.3f" % (covered, kcoverage, gcoverage, wcoverage, score)
        results.sort(lambda a, b: cmp(b[-1], a[-1]))
        for r in results[:args.top]:
            if args.output:
                output.write("%d\t%s\t%.3f\t%.2f\t%.2f\t%.2f\t%.3f\t%.3f\t%.3f\t%.3f\n" % r)
            else:
                print "%32s cov %.3f kcov %.2f gcov %.2f spec %.2f acct %.3f even %.3f score %.3f score2 %.3f" % r[1:]

        if args.output:
            output.flush()
        else:
            sys.stdout.flush()

        if exclude is None:
            exclude = bestKmers
        else:
            exclude = np.unique(np.concatenate((exclude, bestKmers)))
        newKmers = np.setdiff1d(panSampleKmers, exclude, assume_unique=True)
        panSampleCounts = kmerizer.intersect_counts(panSampleKmers, panSampleCounts, newKmers)
        samplePanCounts = kmerizer.intersect_counts(panSampleKmers, samplePanCounts, newKmers)
        panSampleKmers = newKmers
        print >>sys.stderr, panSampleKmers.size, "pan kmers in sample after excluding prior strain"
        if panSampleKmers.size < args.min:
            break

if args.output:
    output.close()