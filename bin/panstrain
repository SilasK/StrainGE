#!/usr/bin/env python
import sys
import argparse
from collections import OrderedDict
import math
from multiprocessing import Pool
import numpy as np
import kmertools
import kmerizer
import h5py


parser = argparse.ArgumentParser()
parser.add_argument("-f", "--fingerprint", help="use minhash fingerprint instead of full kmer set to build graph",
                    action="store_true")
parser.add_argument("-v", "--verbose", action='store_true', help="More output")
parser.add_argument("-c", "--cache", action='store_true', help="Cache strain kmer sets between iterations (uses more memory)")
parser.add_argument("-K", type=int, default=kmertools.DEFAULT_K, help="Kmer size (default: %d)" % (kmertools.DEFAULT_K))
parser.add_argument("-o", "--output", help="output text file (default: standard out)")
parser.add_argument("-i", "--iterations", type=int, default=5, help="max strains to look for (default: 5)")
parser.add_argument("-t", "--top", type=int, default=1, help="How many best matches to print (default: 1)")
parser.add_argument("-s", "--score", type=float, default=0.005, help="minimum score")
parser.add_argument("-e", "--evenness", type=float, default=0.5, help="minimum evenness")
parser.add_argument("-S", "--scoring", choices=("default", "weighted"), default="default", help="scoring algorithm")
parser.add_argument("-r", "--readlength", type=int, default=101, help="Read length (for better coverage estimates, default: 101)")
parser.add_argument("-p", "--threads", type=int, default=1, help="Parallel threads (implies --cache)")
parser.add_argument("pan", help="hdf5 file containing pan genome kmer set")
parser.add_argument("sample", help="Compare similarity of this vs the other strains instead of all vs all")
args = parser.parse_args()

cache = args.cache or args.threads > 1
# coverage normalization factor
covmult = float(args.readlength) / float(args.readlength - args.K + 1)

strainKmerSets = {}

def strainKmerSet(strainName):
    global h5pan, strainKmerSets
    if strainName in strainKmerSets:
        return strainKmerSets[strainName]
    else:
        kset = kmertools.KmerSet()
        kset.load_hdf5(h5pan[strainName])
        if cache:
            strainKmerSets[strainName] = kset
        return kset


def scoreStrain(name):
    global excludeKmers, panSampleKmers, panSampleCounts
    strain = strainKmerSet(name)
    strainKmers = strain.kmers
    strainCounts = strain.counts

    # t0 = time.time()

    if args.fingerprint and excludeKmers is None:
        strainKmers = strain.fingerprint
        strainCounts = np.ones_like(strain.fingerprint, dtype=np.int64)

    if excludeKmers is not None:
        strainKmers = kmerizer.diff(strain.kmers, excludeKmers)
        if float(strainKmers.size) / float(strain.kmers.size) < 0.05:
            return
        strainCounts = kmerizer.intersect_counts(strain.kmers, strain.counts, strainKmers)

    strainSampleKmers = kmerizer.intersect(panSampleKmers, strainKmers)
    if strainSampleKmers.size == 0:
        return
    strainSampleCounts = kmerizer.intersect_counts(panSampleKmers, panSampleCounts, strainKmers)
    strainSampleCount = strainSampleCounts.sum()
    sampleStrainCounts = kmerizer.intersect_counts(strainKmers, strainCounts, panSampleKmers)
    sampleStrainCount = sampleStrainCounts.sum()
    assert strainSampleKmers.size == strainSampleCounts.size == sampleStrainCounts.size, "length mismatch"

    # Fraction of strain kmers in sample
    covered = float(strainSampleKmers.size) / float(strainKmers.size)
    # kmer coverage: mean coverage of every strain kmer that is in the sample
    kcoverage = float(strainSampleCount) / float(strainSampleKmers.size)
    # genome coverage: mean coverage of every strain kmer
    gcoverage = covmult * float(strainSampleCount) / float(strainCounts.sum())

    # converse of covered: what fraction of pangenome sample kmers are in this strain?
    accounted = float(strainSampleKmers.size) / float(panSampleKmers.size)

    # t2 = time.time()

    # Lander-Waterman estimate of percentage covered if uniform
    estCovered = 1.0 - math.exp(-gcoverage)
    # measure of evenness of coverage
    evenness = covered / estCovered

    result = {"name": name,
              "cov": covered,
              "kcov": kcoverage,
              "gcov": gcoverage,
              "acct": accounted,
              "even": evenness}

    if args.scoring == "weighted":
        # Weights of each kmer in strain (inverse of occurrence in pangenome)
        strainPanCounts = kmerizer.intersect_counts(pan.kmers, pan.counts, strainKmers)
        strainWeights = 1.0 / strainPanCounts
        strainTotalWeight = (strainWeights * strainCounts).sum()

        strainSampleWeights = 1.0 / kmerizer.intersect_counts(strainKmers, strainPanCounts, strainSampleKmers)
        countweight = (strainSampleCounts * strainSampleWeights).sum()
        wcoverage = covmult * countweight / strainTotalWeight
        # wsample = countweight / (1.0 / samplePanCounts).sum()
        #
        specificity = wcoverage / gcoverage
        score = covered * accounted * min(specificity, 1 / specificity)
        result["spec"] = specificity
        result["score"] = score
    else:
        score = covered * accounted * evenness
        result["score"] = score

    return result


resultFormats = OrderedDict([("i", "%d"),
                             ("name", "%s"),
                             ("cov", "%.3f"),
                             ("kcov", "%.2f"),
                             ("gcov", "%.2f"),
                             ("acct", "%.3f"),
                             ("even", "%.3f"),
                             ("spec", "%.2f"),
                             ("score", "%.3f")])

print >>sys.stderr, "Loading sample", args.sample
sample = kmertools.kmerSetFromFile(args.sample)

excludeKmers = None

if args.output:
    output = open(args.output, 'w')
else:
    output = sys.stdout

with h5py.File(args.pan, 'r') as h5pan:
    print >>sys.stderr, "Loading pan genome"
    pan = kmertools.KmerSet()
    pan.load_hdf5(h5pan)
    # Strains are groups within hdf5 file
    strainNames = [name for name in h5pan.keys() if isinstance(h5pan[name], h5py.Group)]
    print >>sys.stderr, len(strainNames), "strains,", pan.kmers.size, "kmers in pan genome"

    # common kmers contains all kmers of sample which are in pangenome
    panSampleKmers = kmerizer.intersect(sample.kmers, pan.kmers)
    print >>sys.stderr, panSampleKmers.size, "pan kmers in sample"
    # how often each common kmer occurs in sample
    panSampleCounts = kmerizer.intersect_counts(sample.kmers, sample.counts, panSampleKmers)
    # how often each common kmer occurs in pangenome
    samplePanCounts = kmerizer.intersect_counts(pan.kmers, pan.counts, panSampleKmers)
    assert panSampleKmers.size == panSampleCounts.size == samplePanCounts.size, "Intersection kmers & counts differ in size"

    # release sample from memory
    sample = None

    if cache:
        # preload kmer sets
        print >>sys.stderr, "Loading strains"
        for s in strainNames:
            strainKmerSet(s)

    rKeys = [k for k in resultFormats] # edited by Tim
    rFormats = [resultFormats[k] for k in rKeys]
    print >>output, "\t".join(rKeys)
    for i in range(args.iterations):           
        print >>sys.stderr, "Finding strain", i + 1
        results = []
        bestScore = 0
        bestKset = None

        # loop over strains in pangenome file
        if args.threads > 1:
            pool = Pool(args.threads)
            results = pool.map(scoreStrain, strainNames)
            pool.terminate()
        else:
            results = map(scoreStrain, strainNames)


        results = list(filter(lambda r: r and r["score"] >= args.score and r["even"] >= args.evenness, results))

        if len(results) == 0:
            break

        for r in results:
            r["i"] = i

        results.sort(lambda a, b: cmp(b["score"], a["score"]))
        
        for r in results[:args.top]:
            rValues = tuple((r[k] for k in rKeys))
            print >>output, ("\t".join(rFormats)) % rValues

        if args.output:
            output.flush()
        else:
            sys.stdout.flush()

        bestKmers = strainKmerSet(results[0]["name"]).kmers

        if excludeKmers is None:
            excludeKmers = bestKmers
        else:
            excludeKmers = np.unique(np.concatenate((excludeKmers, bestKmers)))
        #newKmers = np.setdiff1d(panSampleKmers, exclude, assume_unique=True)
        newKmers = kmerizer.diff(panSampleKmers, excludeKmers)
        #assert np.array_equal(newKmers, xxx), "kmerizer.diff bug"
        panSampleCounts = kmerizer.intersect_counts(panSampleKmers, panSampleCounts, newKmers)
        samplePanCounts = kmerizer.intersect_counts(panSampleKmers, samplePanCounts, newKmers)
        panSampleKmers = newKmers
        print >>sys.stderr, panSampleKmers.size, "pan kmers in sample after excluding prior strain"

print >>sys.stderr, 'Done!'

if args.output:
    output.close()