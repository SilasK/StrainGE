#!/usr/bin/env python
import sys
import argparse
import time
import numpy as np
import kmertools
import kmerizer
import math
import h5py


parser = argparse.ArgumentParser()
parser.add_argument("-f", "--fingerprint", help="use minhash fingerprint instead of full kmer set to build graph",
                    action="store_true")
parser.add_argument("-s", "--sample", help="Compare similarity of this vs the other strains instead of all vs all")
parser.add_argument("-p", "--pan", help="hdf5 file containing pan genome kmer set")
parser.add_argument("--secondary", action='store_true', help="Look for secondary strain")
parser.add_argument("-K", type=int, default=kmertools.DEFAULT_K, help="Kmer size")
parser.add_argument("-o", "--output", help="output text file")
parser.add_argument("-i", "--iterations", type=int, default=2, help="how many strains to look for")
parser.add_argument("-t", "--top", type=int, default=5, help="How many best matches to print")
parser.add_argument("-r", "--readlength", type=int, default=101, help="Read length (for better coverage estimates)")
args = parser.parse_args()

def scoreStrain(name, kset, commonKmers, sampleCounts, panCounts, exclude=None):
    """
    :param commonKmers:
    :param sampleCounts:
    :param panCounts:
    :param exclude:
    :return:
    """

    t0 = time.time()

    covmult = float(args.readlength) / float(args.readlength - args.K + 1)

    if args.fingerprint:
        strainKmers = kset.fingerprint
        strainCounts = np.ones_like(kset.fingerprint, dtype=np.int64)
    else:
        strainKmers = kset.kmers
        strainCounts = kset.counts

    if exclude is not None:
        keepers = np.setdiff1d(strainKmers, exclude, assume_unique=True)
        if float(keepers.size) / float(strainKmers.size) < 0.05:
            return None
        strainCounts = kmerizer.intersect_counts(strainKmers, strainCounts, keepers)
        strainKmers = keepers

    t1 = time.time()

    kmers = kmerizer.intersect(commonKmers, strainKmers)
    samplec = kmerizer.intersect_counts(commonKmers, sampleCounts, strainKmers)
    strainc = kmerizer.intersect_counts(strainKmers, strainCounts, commonKmers)
    if strainc.sum() == 0:
        return None
    assert kmers.size == samplec.size, "length mismatch"

    covered = float(kmers.size) / float(strainKmers.size)
    # kmer coverage: mean coverage of every strain kmer that is in the sample
    kcoverage = float(samplec.sum()) / float(strainc.sum())
    # genome coverage: mean coverage of every strain kmer
    gcoverage = covmult * float(samplec.sum()) / float(strainCounts.sum())

    t2 = time.time()


    # Lander-Waterman estimate of percentage covered if uniform
    estCovered = 1.0 - math.exp(-gcoverage)
    # measure of evenness of coverage
    evenness = covered / estCovered

    # Weights of each kmer in strain
    strainWeights = 1.0 / kmerizer.intersect_counts(pan.kmers, pan.counts, strainKmers)
    # strainWeights = strainWeights * strainWeights
    assert strainWeights.size == strainKmers.size, "Strain has kmers not in pan genome"
    # Total weight of strain
    strainWeight = (strainWeights * strainCounts).sum()
    weights = 1.0 / kmerizer.intersect_counts(commonKmers, panCounts, strainKmers)
    assert kmers.size == weights.size, "kmers/weights mismatch"

    # weighted coverage: sample coverage weighted by inverse kmer occurance in pan genome
    countweights = (samplec * weights)
    wcoverage = covmult * countweights.sum() / strainWeight

    specificity = wcoverage / gcoverage if gcoverage > wcoverage else gcoverage / wcoverage
    score = wcoverage * evenness

    t3 = time.time()
    #print 'Times:', t1-t0, t2-t1, t3-t2

    result = (name, covered, kcoverage, gcoverage, wcoverage, evenness, score)
    return result, strainKmers


print "Loading sample", args.sample
sample = kmertools.kmerSetFromFile(args.sample)



exclude = None

with h5py.File(args.pan, 'r') as h5:
    print "Loading pan genome"
    pan = kmertools.KmerSet()
    pan.load_hdf5(h5)

    print "Create sample intersection with pan genome"
    commonKmers = kmerizer.intersect(sample.kmers, pan.kmers)
    print commonKmers.size, "pan kmers in sample"
    sampleCounts = kmerizer.intersect_counts(sample.kmers, sample.counts, commonKmers)
    panCounts = kmerizer.intersect_counts(pan.kmers, pan.counts, commonKmers)
    assert commonKmers.size == sampleCounts.size == panCounts.size, "Intersection kmers & counts differ in size"

    for i in range(args.iterations):
        print "Finding strain", i + 1

        results = []
        bestScore = 0
        bestKset = None

        for name in h5.keys():
            if not isinstance(h5[name], h5py.Group):
                continue
            kset = kmertools.KmerSet()
            kset.load_hdf5(h5[name])
            result = scoreStrain(name, kset, commonKmers, sampleCounts, panCounts, exclude=exclude)
            if result:
                metrics, kmers = result
                score = metrics[-1]
                results.append(metrics)
                if score > bestScore:
                    bestScore = score
                    bestKmers = kmers
        # print name, "covered: %.3f kcov: %.2f gcov: %.2f wcov: %.2f score: %.3f" % (covered, kcoverage, gcoverage, wcoverage, score)
        results.sort(lambda a, b: cmp(b[-1], a[-1]))
        for r in results[:args.top]:
            print "%s covered: %.3f kcov: %.2f gcov: %.2f wcov: %.2f even: %.3f score: %.3f" % r
            # print >>output, "%s\t%.3f\t%.2f\t%.2f\t%.2f\t%.3f" % (r[0], r[1], r[2], r[3], r[4], r[5])
        sys.stdout.flush()
        if exclude is None:
            exclude = bestKmers
        else:
            exclude, ignore = kmerizer.merge_counts(exclude, np.ones_like(exclude), bestKmers, np.ones_like(bestKmers))
        newKmers = np.setdiff1d(commonKmers, exclude, assume_unique=True)
        sampleCounts = kmerizer.intersect_counts(commonKmers, sampleCounts, newKmers)
        panCounts = kmerizer.intersect_counts(commonKmers, panCounts, newKmers)
        commonKmers = newKmers
        print commonKmers.size, "pan kmers in sample after excluding prior strain"



