#!/usr/bin/env python
import sys
import argparse
# import time
import numpy as np
import kmertools
import kmerizer
import math
import h5py


parser = argparse.ArgumentParser()
parser.add_argument("-f", "--fingerprint", help="use minhash fingerprint instead of full kmer set to build graph",
                    action="store_true")
parser.add_argument("-v", "--verbose", action='store_true', help="More output")
parser.add_argument("-c", "--cache", action='store_true', help="Cache strain kmer sets between iterations (uses more memory)")
parser.add_argument("-K", type=int, default=kmertools.DEFAULT_K, help="Kmer size (default: %d)" % (kmertools.DEFAULT_K))
parser.add_argument("-o", "--output", help="output text file (default: standard out)")
parser.add_argument("-i", "--iterations", type=int, default=5, help="max strains to look for (default: 5)")
parser.add_argument("-t", "--top", type=int, default=1, help="How many best matches to print (default: 1)")
parser.add_argument("-s", "--score", type=float, default=0.005, help="minimum score")
parser.add_argument("-e", "--evenness", type=float, default=0.5, help="minimum evenness")
parser.add_argument("-S", "--scoring", choices=("default", "weighted"), default="default", help="scoring algorithm")
parser.add_argument("-r", "--readlength", type=int, default=101, help="Read length (for better coverage estimates, default: 101)")
parser.add_argument("pan", help="hdf5 file containing pan genome kmer set")
parser.add_argument("sample", help="Compare similarity of this vs the other strains instead of all vs all")
args = parser.parse_args()


# coverage normalization factor
covmult = float(args.readlength) / float(args.readlength - args.K + 1)

print >>sys.stderr, "Loading sample", args.sample
sample = kmertools.kmerSetFromFile(args.sample)

exclude = None

if args.output:
    output = open(args.output, 'w')
else:
    output = sys.stdout

with h5py.File(args.pan, 'r') as h5:
    print >>sys.stderr, "Loading pan genome"
    pan = kmertools.KmerSet()
    pan.load_hdf5(h5)

    # common kmers contains all kmers of sample which are in pangenome
    panSampleKmers = kmerizer.intersect(sample.kmers, pan.kmers)
    print >>sys.stderr, panSampleKmers.size, "pan kmers in sample"
    # how often each common kmer occurs in sample
    panSampleCounts = kmerizer.intersect_counts(sample.kmers, sample.counts, panSampleKmers)
    # how often each common kmer occurs in pangenome
    samplePanCounts = kmerizer.intersect_counts(pan.kmers, pan.counts, panSampleKmers)
    assert panSampleKmers.size == panSampleCounts.size == samplePanCounts.size, "Intersection kmers & counts differ in size"

    # release sample from memory
    sample = None
    strainKmerSets = {}

    print 

    for i in range(args.iterations):
        print >>sys.stderr, "Finding strain", i + 1
        results = []
        bestScore = 0
        bestKset = None

        # loop over strains in pangenome file
        for name in h5.keys():
            # Strain KmerSets are in groups
            if not isinstance(h5[name], h5py.Group):
                continue

            if name in strainKmerSets:
                strain = strainKmerSets[name]
            else:
                strain = kmertools.KmerSet()
                strain.load_hdf5(h5[name])

            # t0 = time.time()

            if args.fingerprint and exclude is None:
                strain.kmers = strain.fingerprint
                strain.counts = np.ones_like(strain.fingerprint, dtype=np.int64)


            if exclude is not None:
                keepers = np.setdiff1d(strain.kmers, exclude, assume_unique=True)
                if float(keepers.size) / float(strain.kmers.size) < 0.05:
                    continue
                strain.counts = kmerizer.intersect_counts(strain.kmers, strain.counts, keepers)
                strain.kmers = keepers

            if args.cache:
                strainKmerSets[name] = strain


            # t1 = time.time()

            strainSampleKmers = kmerizer.intersect(panSampleKmers, strain.kmers)
            if strainSampleKmers.size == 0:
                continue
            strainSampleCounts = kmerizer.intersect_counts(panSampleKmers, panSampleCounts, strain.kmers)
            strainSampleCount = strainSampleCounts.sum()
            sampleStrainCounts = kmerizer.intersect_counts(strain.kmers, strain.counts, panSampleKmers)
            sampleStrainCount = sampleStrainCounts.sum()
            assert strainSampleKmers.size == strainSampleCounts.size == sampleStrainCounts.size, "length mismatch"

            # Fraction of strain kmers in sample
            covered = float(strainSampleKmers.size) / float(strain.kmers.size)
            # kmer coverage: mean coverage of every strain kmer that is in the sample
            kcoverage = float(strainSampleCount) / float(strainSampleKmers.size)
            # genome coverage: mean coverage of every strain kmer
            gcoverage = covmult * float(strainSampleCount) / float(strain.counts.sum())

            # converse of covered: what fraction of pangenome sample kmers are in this strain?
            accounted = float(strainSampleKmers.size) / float(panSampleKmers.size)

            # t2 = time.time()

            # Lander-Waterman estimate of percentage covered if uniform
            estCovered = 1.0 - math.exp(-gcoverage)
            # measure of evenness of coverage
            evenness = covered / estCovered

            if args.scoring == "weighted":
                # Weights of each kmer in strain (inverse of occurrence in pangenome)
                strainPanCounts = kmerizer.intersect_counts(pan.kmers, pan.counts, strain.kmers)
                strainWeights = 1.0 / strainPanCounts
                strainTotalWeight = (strainWeights * strain.counts).sum()

                strainSampleWeights = 1.0 / kmerizer.intersect_counts(strain.kmers, strainPanCounts, strainSampleKmers)
                countweight = (strainSampleCounts * strainSampleWeights).sum()
                wcoverage = covmult * countweight / strainTotalWeight
                # wsample = countweight / (1.0 / samplePanCounts).sum()
                #
                specificity = wcoverage / gcoverage
                score = covered * accounted * min(specificity, 1/specificity)
                result = (i, name, covered, kcoverage, gcoverage, accounted, evenness, specificity, score)
                resultNames = ("i", "name", "cov", "kcov", "gcov", "acct", "even", "spec", "score")
                resultFormats = ("%d", "%s", "%.3f", "%.2f", "%.2f", "%.3f", "%.3f", "%.2f", "%.3f")
            else:
                score = covered * accounted * evenness
                result = (i, name, covered, kcoverage, gcoverage, accounted, evenness, score)
                resultNames = ("i", "name", "cov", "kcov", "gcov", "acct", "even", "score")
                resultFormats = ("%d", "%s", "%.3f", "%.2f", "%.2f", "%.3f", "%.3f", "%.3f")

            # scoring thresholds
            if score < args.score or evenness < args.evenness:
                continue

            results.append(result)

            # If this is the winner, keep the kmers around
            if result[-1] > bestScore:
                bestScore = result[-1]
                bestKmers = strainSampleKmers

            if args.verbose:
                print >>sys.stderr, " ".join([r[0] + "=" + (r[1] % r[2]) for r in zip(resultNames, resultFormats, result)])
                #print >>sys.stderr, " ".join([str(r) for r in zip(resultNames, resultFormats, result)])

        if bestScore == 0:
            break
        # print name, "covered: %.3f kcov: %.2f gcov: %.2f wcov: %.2f score: %.3f" % (covered, kcoverage, gcoverage, wcoverage, score)
        results.sort(lambda a, b: cmp(b[-1], a[-1]))
        if i == 0:
            print >>output, "\t".join(resultNames)
        for r in results[:args.top]:
            print >>output, "\t".join(resultFormats) % r

        if args.output:
            output.flush()
        else:
            sys.stdout.flush()

        if exclude is None:
            exclude = bestKmers
        else:
            exclude = np.unique(np.concatenate((exclude, bestKmers)))
        newKmers = np.setdiff1d(panSampleKmers, exclude, assume_unique=True)
        panSampleCounts = kmerizer.intersect_counts(panSampleKmers, panSampleCounts, newKmers)
        samplePanCounts = kmerizer.intersect_counts(panSampleKmers, samplePanCounts, newKmers)
        panSampleKmers = newKmers
        print >>sys.stderr, panSampleKmers.size, "pan kmers in sample after excluding prior strain"

print >>sys.stderr, 'Done!'

if args.output:
    output.close()